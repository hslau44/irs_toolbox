{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to demonstrate how this library works\n",
    "\n",
    "\n",
    "# 1. Structure \n",
    "\n",
    "root\\\n",
    "├── callbacks // here you can create your custom callbacks \\\n",
    "├── checkpoint // were we store the trained models \\\n",
    "├── data // quick data import and transformation pipeline \\\n",
    "│ ├── selection // data selection for train-validation-test split\\\n",
    "│ ├── transformation // custom transformation compatible with torchvision.transform\\\n",
    "│ ├── torchData // custom torch Dataset and DataLoader\\\n",
    "│ ├── custom_data.py // data for specific format\\\n",
    "│ ├── load_npy_format.py // tranform and load csv files into npy files\\\n",
    "│ └── utils.py\\\n",
    "├── laboratory // notebooks for running experiments\\\n",
    "│ ├── saved_model \\\n",
    "│ └── record \\\n",
    "├── losses // custom losses\\\n",
    "├── metrics // custom metrics\\\n",
    "├── main.py **to be edited**\\\n",
    "├── models // quick default model setup \\\n",
    "│ ├── baseline.py // baseline models\\\n",
    "│ ├── cnn.py // torchvision CNN models\\\n",
    "│ ├── self_supervised.py // torch.nn.module for contrastive learning, **to be depreciated** \\\n",
    "│ ├── temproal.py // CNN-LSTM\\\n",
    "│ └── utils.py // utility torch.nn.module\\\n",
    "├── playground.ipynb // fast experiment with things\\\n",
    "├── README.md\\\n",
    "├── test // to be implemented\\\n",
    "└── utils.py // utilities functions\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the notebook all used libraries are pre-loaded, this demo instead load them one by one\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Some notebooks are not setup in root, this is to add to the system path  \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# gpu setting\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(DEVICE)\n",
    "device = DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please edit the following arguments \n",
    "data_dir = 'E:\\\\external_data\\\\opera_csi\\\\Session_2\\\\experiment_data\\\\experiment_data\\\\exp_7_amp_spec_only\\\\npy_format' \n",
    "readtype = 'npy' # type of file, currently support 'csv' or 'npy'\n",
    "splitchar = '\\\\'\n",
    "fpath = '.\\\\laboratory' # for saving models and records "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of the **filepath-dataframe** consist of the fullpath of the file and its corresponding file based on its filename or folder level. The standard and the most versatile way is to use `filepath_dataframe` from `data.utils`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullpath</th>\n",
       "      <th>class_1</th>\n",
       "      <th>class_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "      <td>bodyrotate</td>\n",
       "      <td>nuc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "      <td>bodyrotate</td>\n",
       "      <td>nuc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "      <td>bodyrotate</td>\n",
       "      <td>nuc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "      <td>bodyrotate</td>\n",
       "      <td>nuc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "      <td>bodyrotate</td>\n",
       "      <td>nuc1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            fullpath     class_1 class_2\n",
       "0  E:\\external_data\\opera_csi\\Session_2\\experimen...  bodyrotate    nuc1\n",
       "1  E:\\external_data\\opera_csi\\Session_2\\experimen...  bodyrotate    nuc1\n",
       "2  E:\\external_data\\opera_csi\\Session_2\\experimen...  bodyrotate    nuc1\n",
       "3  E:\\external_data\\opera_csi\\Session_2\\experimen...  bodyrotate    nuc1\n",
       "4  E:\\external_data\\opera_csi\\Session_2\\experimen...  bodyrotate    nuc1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.utils import filepath_dataframe\n",
    "\n",
    "# this is the most versatile way to read the files, folder levels represent classes  \n",
    "df = filepath_dataframe(data_dir,splitchar)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuctions in `data.custom_data` is created for recently publish data. It consists of `filepath_dataframe` to create filepath-dataframe that extract more information from the filename. `nucPaired_fpDataframe` is for joint data based on the NUC unit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5812, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullpath</th>\n",
       "      <th>exp</th>\n",
       "      <th>person</th>\n",
       "      <th>room</th>\n",
       "      <th>activity</th>\n",
       "      <th>index</th>\n",
       "      <th>nuc</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "      <td>5</td>\n",
       "      <td>One</td>\n",
       "      <td>1</td>\n",
       "      <td>bodyrotate</td>\n",
       "      <td>10</td>\n",
       "      <td>NUC1</td>\n",
       "      <td>exp_005_person_One_room_1_bodyrotate_index_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "      <td>5</td>\n",
       "      <td>One</td>\n",
       "      <td>1</td>\n",
       "      <td>bodyrotate</td>\n",
       "      <td>11</td>\n",
       "      <td>NUC1</td>\n",
       "      <td>exp_005_person_One_room_1_bodyrotate_index_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "      <td>5</td>\n",
       "      <td>One</td>\n",
       "      <td>1</td>\n",
       "      <td>bodyrotate</td>\n",
       "      <td>12</td>\n",
       "      <td>NUC1</td>\n",
       "      <td>exp_005_person_One_room_1_bodyrotate_index_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "      <td>5</td>\n",
       "      <td>One</td>\n",
       "      <td>1</td>\n",
       "      <td>bodyrotate</td>\n",
       "      <td>13</td>\n",
       "      <td>NUC1</td>\n",
       "      <td>exp_005_person_One_room_1_bodyrotate_index_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "      <td>5</td>\n",
       "      <td>One</td>\n",
       "      <td>1</td>\n",
       "      <td>bodyrotate</td>\n",
       "      <td>14</td>\n",
       "      <td>NUC1</td>\n",
       "      <td>exp_005_person_One_room_1_bodyrotate_index_14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            fullpath  exp person  room  \\\n",
       "0  E:\\external_data\\opera_csi\\Session_2\\experimen...    5    One     1   \n",
       "1  E:\\external_data\\opera_csi\\Session_2\\experimen...    5    One     1   \n",
       "2  E:\\external_data\\opera_csi\\Session_2\\experimen...    5    One     1   \n",
       "3  E:\\external_data\\opera_csi\\Session_2\\experimen...    5    One     1   \n",
       "4  E:\\external_data\\opera_csi\\Session_2\\experimen...    5    One     1   \n",
       "\n",
       "     activity  index   nuc                                            key  \n",
       "0  bodyrotate     10  NUC1  exp_005_person_One_room_1_bodyrotate_index_10  \n",
       "1  bodyrotate     11  NUC1  exp_005_person_One_room_1_bodyrotate_index_11  \n",
       "2  bodyrotate     12  NUC1  exp_005_person_One_room_1_bodyrotate_index_12  \n",
       "3  bodyrotate     13  NUC1  exp_005_person_One_room_1_bodyrotate_index_13  \n",
       "4  bodyrotate     14  NUC1  exp_005_person_One_room_1_bodyrotate_index_14  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.custom_data import filepath_dataframe\n",
    "\n",
    "# this is specifically for recently publised data  \n",
    "df = filepath_dataframe(data_dir,splitchar)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2906, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullpath_x</th>\n",
       "      <th>exp</th>\n",
       "      <th>person</th>\n",
       "      <th>room</th>\n",
       "      <th>activity</th>\n",
       "      <th>index</th>\n",
       "      <th>nuc</th>\n",
       "      <th>key</th>\n",
       "      <th>fullpath_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "      <td>5</td>\n",
       "      <td>One</td>\n",
       "      <td>1</td>\n",
       "      <td>bodyrotate</td>\n",
       "      <td>10</td>\n",
       "      <td>NUC1</td>\n",
       "      <td>exp_005_person_One_room_1_bodyrotate_index_10</td>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "      <td>5</td>\n",
       "      <td>One</td>\n",
       "      <td>1</td>\n",
       "      <td>bodyrotate</td>\n",
       "      <td>11</td>\n",
       "      <td>NUC1</td>\n",
       "      <td>exp_005_person_One_room_1_bodyrotate_index_11</td>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "      <td>5</td>\n",
       "      <td>One</td>\n",
       "      <td>1</td>\n",
       "      <td>bodyrotate</td>\n",
       "      <td>12</td>\n",
       "      <td>NUC1</td>\n",
       "      <td>exp_005_person_One_room_1_bodyrotate_index_12</td>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "      <td>5</td>\n",
       "      <td>One</td>\n",
       "      <td>1</td>\n",
       "      <td>bodyrotate</td>\n",
       "      <td>13</td>\n",
       "      <td>NUC1</td>\n",
       "      <td>exp_005_person_One_room_1_bodyrotate_index_13</td>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "      <td>5</td>\n",
       "      <td>One</td>\n",
       "      <td>1</td>\n",
       "      <td>bodyrotate</td>\n",
       "      <td>14</td>\n",
       "      <td>NUC1</td>\n",
       "      <td>exp_005_person_One_room_1_bodyrotate_index_14</td>\n",
       "      <td>E:\\external_data\\opera_csi\\Session_2\\experimen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          fullpath_x  exp person  room  \\\n",
       "0  E:\\external_data\\opera_csi\\Session_2\\experimen...    5    One     1   \n",
       "1  E:\\external_data\\opera_csi\\Session_2\\experimen...    5    One     1   \n",
       "2  E:\\external_data\\opera_csi\\Session_2\\experimen...    5    One     1   \n",
       "3  E:\\external_data\\opera_csi\\Session_2\\experimen...    5    One     1   \n",
       "4  E:\\external_data\\opera_csi\\Session_2\\experimen...    5    One     1   \n",
       "\n",
       "     activity  index   nuc                                            key  \\\n",
       "0  bodyrotate     10  NUC1  exp_005_person_One_room_1_bodyrotate_index_10   \n",
       "1  bodyrotate     11  NUC1  exp_005_person_One_room_1_bodyrotate_index_11   \n",
       "2  bodyrotate     12  NUC1  exp_005_person_One_room_1_bodyrotate_index_12   \n",
       "3  bodyrotate     13  NUC1  exp_005_person_One_room_1_bodyrotate_index_13   \n",
       "4  bodyrotate     14  NUC1  exp_005_person_One_room_1_bodyrotate_index_14   \n",
       "\n",
       "                                          fullpath_y  \n",
       "0  E:\\external_data\\opera_csi\\Session_2\\experimen...  \n",
       "1  E:\\external_data\\opera_csi\\Session_2\\experimen...  \n",
       "2  E:\\external_data\\opera_csi\\Session_2\\experimen...  \n",
       "3  E:\\external_data\\opera_csi\\Session_2\\experimen...  \n",
       "4  E:\\external_data\\opera_csi\\Session_2\\experimen...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.custom_data import nucPaired_fpDataframe\n",
    "\n",
    "pair_df = nucPaired_fpDataframe(df)\n",
    "print(pair_df.shape)\n",
    "pair_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found the biggest bottlneck for loading the data is the format, therefore I advise to save the data into .npy format and use the newly generated data instead. This can speed up the loading process by 100 times. Please copy the following command and execute on root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./data/load_npy_format.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have filepath-dataframe that represent the actual data, we can perform data selection by manipulate the filepath-dataframe. `data.selection` is a group of function to split the dataframe into train-validation-test set for the **newly published data**. `Selection` is the standardised way to split dataset, which consists arguments:\n",
    "\n",
    "- split (str): spliting method, available are `'random'` or `'loov'` (leave one participant out)\n",
    "- test_sub (str/float): depend on the spliting method, if `'random'`, it is the percentage of that the data becoming test set, if `'loov'`, it is the 'person' in the filepath-dataframe to become test subject\n",
    "- val_sub (str/float): depend on the spliting method, if `'random'`, it is the percentage of that the data becoming test set, if `'loov'`, it is the `'person'` in the filepath-dataframe to become test subject, if `None`, the validation data = None\n",
    "- nuc (str/list): nuc to be included \n",
    "- room (int/list): room to be included\n",
    "- sample_per_class (int/bool): selecting number of sample for each class, if None, this process will not proceed\n",
    "- \\*\\*kwarg: torch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (1324, 8)\tValidation size: (190, 8)\tTest size: (162, 8)\n"
     ]
    }
   ],
   "source": [
    "from data.selection import Selection\n",
    "\n",
    "# standardised way to split dataset \n",
    "data_selection = Selection(split='random',test_sub=0.2,val_sub=0.1,nuc='NUC1',room=1,sample_per_class=None)\n",
    "df_train,df_val,df_test = data_selection(df)\n",
    "print(f\"Train size: {df_train.shape}\\tValidation size: {df_val.shape}\\tTest size: {df_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For quick setup, there are SelectionSet_1 to 5 for serval setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (1433, 8)\tValidation size: (173, 8)\tTest size: (132, 8)\n"
     ]
    }
   ],
   "source": [
    "from data.selection import SelectionSet_1,\n",
    "\n",
    "# Alternative predefined selection, total of 5 available \n",
    "data_selection = SelectionSet_1()\n",
    "df_train,df_val,df_test = data_selection(df)\n",
    "print(f\"Train size: {df_train.shape}\\tValidation size: {df_val.shape}\\tTest size: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original data may not have our desire format for the algorithm. `data.transformation` is designed based on **torchvision** transformation pipeline, so each data is processed according after reading from the file. Currently there are three transformation pipeline available, you can also use your own pipeline, given it is compatible with [torchvision](https://pytorch.org/vision/stable/transforms.html#:~:text=torchvision.transforms%20Transforms%20are%20common%20image%20transformations.%20They%20can,functional%20transforms%20give%20fine-grained%20control%20over%20the%20transformations.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.transformation import Transform_CnnLstmS,Transform_CnnS,Transform_Cnn\n",
    "\n",
    "transform = Transform_CnnS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have three filepath-dataframes, we will create `DataLoading` that help us to setup the our predefined dataLoader, it consists of:\n",
    "\n",
    "- transform (torchvision.transforms.transforms.Compose) - transformation pipeline\n",
    "- batch_size (int) - batch size of train and validation set\n",
    "- readtype (str) - currently support 'csv' or 'npy'\n",
    "- load_data (bool) - please set it as False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.torchData import DataLoading\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 0\n",
    "\n",
    "data_loading = DataLoading(transform=transform,batch_size=batch_size,readtype=readtype,\n",
    "                           num_workers=num_workers,drop_last=True)\n",
    "test_loading = DataLoading(transform=transform,batch_size=len(df_test),readtype=readtype,\n",
    "                           num_workers=num_workers,drop_last=True)\n",
    "\n",
    "train_loader = data_loading(df_train)\n",
    "val_loader   = data_loading(df_val)\n",
    "test_loader  = test_loading(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader - X: torch.Size([64, 1, 70, 1600]) \t Y: torch.Size([64])\n",
      "test_loader  - X: torch.Size([132, 1, 70, 1600]) \t Y: torch.Size([132])\n"
     ]
    }
   ],
   "source": [
    "def test_dataloading(loader):\n",
    "    for x,y in loader:\n",
    "        break\n",
    "    return x.shape,y.shape\n",
    "\n",
    "print(f\"train_loader - X: {test_dataloading(train_loader)[0]} \\t Y: {test_dataloading(train_loader)[1]}\")\n",
    "print(f\"test_loader  - X: {test_dataloading(test_loader)[0]} \\t Y: {test_dataloading(test_loader)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "`PairDataLoading` is similar to `DataLoading`, but it only takes filename-dataframe generated from `nucPaired_fpDataframe` (with columns `fullpath_x` and `fullpath_y`). We have extra argument `supervision` for whether it returns the label, due to the later process, please alway set it True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.torchData import PairDataLoading\n",
    "\n",
    "pdf_train,pdf_val,pdf_test = data_selection(pair_df)\n",
    "pretrain_loading = PairDataLoading(transform=transform,\n",
    "                                   batch_size=batch_size,\n",
    "                                   readtype=readtype,\n",
    "                                   supervision=True,\n",
    "                                   num_workers=num_workers,\n",
    "                                   drop_last=True)\n",
    "\n",
    "\n",
    "pretrain_loader = pretrain_loading(pdf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader - \n",
      "X1: torch.Size([64, 1, 70, 1600]) \n",
      "X2: torch.Size([64, 1, 70, 1600]) \n",
      "Y: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "def test_dataloading(loader):\n",
    "    for x1,x2,y in loader:\n",
    "        break\n",
    "    return x1.shape,x2.shape,y.shape\n",
    "\n",
    "print(f\"train_loader - \\nX1: {test_dataloading(pretrain_loader)[0]} \\nX2: {test_dataloading(pretrain_loader)[1]} \\nY: {test_dataloading(pretrain_loader)[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a builder, a callable function that take no arguments and returns model and latent size, instead of the model itself. The easier way is by **lambda-anonymous-function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cnn import create_alexnet\n",
    "\n",
    "builder = lambda: create_alexnet(output_size=(1,6))\n",
    "model_fname = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Contrastive pretraining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 >>>>>>>>>>>>>>>>>>>>>> loss: 0.48631221055984497\n"
     ]
    }
   ],
   "source": [
    "from training.contrastive_pretraining import Contrastive_PreTraining\n",
    "\n",
    "supervision = True\n",
    "temperature = 0.1\n",
    "model_fname= os.path.join(fpath,'saved_model/test_model')\n",
    "\n",
    "# Setup for NT-Xent\n",
    "clr = Contrastive_PreTraining(\n",
    "    encoder_builder=builder,\n",
    "    batch_size=batch_size,\n",
    "    supervision=supervision,\n",
    "    temperature=temperature\n",
    ")\n",
    "\n",
    "# Pretraining with NT-Xent\n",
    "encoder = clr.train(train_loader=pretrain_loader,\n",
    "                    epochs=1,\n",
    "                    rtn_history=False,\n",
    "                    device=device)\n",
    "\n",
    "# Save and delete model \n",
    "torch.save(encoder.state_dict(),model_fname)\n",
    "del encoder, clr, pretrain_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Standard/Fine-Tuning\n",
    "\n",
    "To standardised the record, we use [poutyne](https://poutyne.org/) for fine-tuning and supervising learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`training.finetuning.FineTuneCNN` is an Encoder Decoder Architecture (nn.Module), it serves two functions: fine-tuning, standard training and loov. It \n",
    "1. Create a empty encoder with `encoder_builder`\n",
    "2. It loads the state dictionary from `model_path` into the encoder, and freeze it. If `model_path` is None, no information will be loaded into the encoder\n",
    "3. Create a decoder with latent size, `hidden layer` and `n_classes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.finetuning import FineTuneCNN\n",
    "\n",
    "hidden_layer=128\n",
    "\n",
    "model = FineTuneCNN(model_path=model_fname,\n",
    "                    encoder_builder=builder,\n",
    "                    hidden_layer=hidden_layer,\n",
    "                    n_classes=df.activity.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mEpoch: \u001b[36m1/1 \u001b[35mStep: \u001b[36m22/22 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m38.10s \u001b[35mloss:\u001b[94m 2749.430311\u001b[35m acc:\u001b[94m 37.215909\u001b[35m fscore_micro:\u001b[94m 0.372159\u001b[35m fscore_macro:\u001b[94m 0.205339\u001b[35m val_loss:\u001b[94m 4002.342285\u001b[35m val_acc:\u001b[94m 16.666668\u001b[35m val_fscore_micro:\u001b[94m 0.166667\u001b[35m val_fscore_macro:\u001b[94m 0.047619\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import poutyne\n",
    "from poutyne import Model,Experiment\n",
    "\n",
    "# train with poutyne\n",
    "finetune_epochs = 1\n",
    "\n",
    "mdl = Model(model,'adam','cross_entropy',\n",
    "            batch_metrics=['accuracy'],\n",
    "            epoch_metrics=[poutyne.F1('micro'),poutyne.F1('macro')]).to(device)\n",
    "history = mdl.fit_generator(train_generator=train_loader,valid_generator=test_loader,epochs=finetune_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>time</th>\n",
       "      <th>acc</th>\n",
       "      <th>fscore_micro</th>\n",
       "      <th>fscore_macro</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_fscore_micro</th>\n",
       "      <th>val_fscore_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2749.430311</td>\n",
       "      <td>38.100532</td>\n",
       "      <td>37.215909</td>\n",
       "      <td>0.372159</td>\n",
       "      <td>0.205339</td>\n",
       "      <td>4002.342285</td>\n",
       "      <td>16.666668</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch         loss       time        acc  fscore_micro  fscore_macro  \\\n",
       "0      1  2749.430311  38.100532  37.215909      0.372159      0.205339   \n",
       "\n",
       "      val_loss    val_acc  val_fscore_micro  val_fscore_macro  \n",
       "0  4002.342285  16.666668          0.166667          0.047619  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. LOOV validation\n",
    "\n",
    "`validation.loov.leaveOneOut_crossValidation` takes FineTuneCNN `training.finetuning.FineTuneCNN`, filepath-dataframe `dataframe`, transformation pipeline to perfrom Leave-One-Participant-Out Validation. It automates the data preparation, initiate the model and train with poutyne.Model module.  Experimental variables can be setup as **kwargs**, here are the keywords and default values \n",
    "\n",
    "- nuc = 'NUC1'\n",
    "- room = 1\n",
    "- batch_size = 128\n",
    "- readtype = 'npy'\n",
    "- num_workers = 0\n",
    "- optimizer = 'adam'\n",
    "- loss = 'cross_entropy'\n",
    "- batch_metrics = \\['accuracy'\\]\n",
    "- epoch_metrics = \\[poutyne.F1('micro'),poutyne.F1('macro')\\]\n",
    "- epochs = 250\n",
    "- device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validation.loov import leaveOneOut_crossValidation\n",
    "\n",
    "records = leaveOneOut_crossValidation(model,df,transform,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For individual training and validation, please follow the notebooks in `./laboratory`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
