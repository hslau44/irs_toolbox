{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import glob\n",
    "import seaborn as sns  # for heatmaps\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cross_validation(item_func,X,y,n_splits):\n",
    "\n",
    "    acc_score = []\n",
    "\n",
    "    kf = KFold(n_splits)\n",
    "    \n",
    "    for train_index , test_index in kf.split(X):\n",
    "        X_train , X_test = X[train_index], X[test_index]\n",
    "        y_train , y_test = y[train_index], y[test_index]\n",
    "        train_loader, test_loader = create_dataloader(X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        # create model \n",
    "        model,optimizer,criterion = item_func()\n",
    "        \n",
    "        # train model\n",
    "        model.fit(X_train,y_train)\n",
    "        pred_values = model.predict(X_test)\n",
    "        \n",
    "        # evaluate\n",
    "        acc = accuracy_score(pred_values , y_test)\n",
    "        acc_score.append(acc)\n",
    "\n",
    "    avg_acc_score = sum(acc_score)/k\n",
    "\n",
    "    print('accuracy of each fold - {}'.format(acc_score))\n",
    "    print('Avg accuracy : {}'.format(avg_acc_score))\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(p1,p2,t=1):\n",
    "    val = p1.dot(p2.transpose())/t\n",
    "    val = np.exp(val)\n",
    "    val = -np.log(np.diag(val)/np.sum(val,axis=1))\n",
    "    return val\n",
    "\n",
    "p1 = np.array([\n",
    " [ 0.70374682, -0.18682394, -0.68544673],\n",
    " [ 0.15465702,  0.32303224,  0.93366556],\n",
    " [ 0.53043332, -0.83523217, -0.14500935],\n",
    " [ 0.68285685, -0.73054075,  0.00409143],\n",
    " [ 0.76652431,  0.61500886,  0.18494479]])\n",
    "\n",
    "p2 = p1 + 0.1*np.random.random(p1.shape)\n",
    "\n",
    "# contrastive_loss(p1,p2,0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def contrastive_loss(z1,z2,t=1):\n",
    "    \"\"\"\n",
    "    One to N\n",
    "    \"\"\"\n",
    "    a = torch.mm(z1,z2.transpose(0,1))\n",
    "    b = torch.norm(z1,dim=1)*torch.norm(z2,dim=1)\n",
    "    sim_mat = torch.div(a,b)\n",
    "    mask = torch.ones_like(sim_mat,dtype=bool).fill_diagonal_(0)\n",
    "    pos = torch.diag(sim_mat).reshape(-1,1)\n",
    "    neg = sim_mat[mask].reshape(pos.shape[0],-1)\n",
    "    logits = torch.cat((pos, neg), dim=1)\n",
    "    labels = torch.zeros(pos.shape[0]).long()\n",
    "    loss = torch.nn.CrossEntropyLoss()(logits,labels)\n",
    "    return loss\n",
    "\n",
    "z1 = torch.tensor(p1)\n",
    "z2 = torch.tensor(p2)\n",
    "z3 = torch.zeros_like(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self,feature_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.linear = nn.Linear(feature_size,1) \n",
    "\n",
    "    def forward(self,X):\n",
    "        assert len(X.shape) == 3\n",
    "        a = self.linear(X)\n",
    "        a = torch.relu(a)\n",
    "        a = F.softmax(a,dim=1)\n",
    "        return a*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(d):\n",
    "    d = np.array(d)\n",
    "    ls = d[0]\n",
    "    for new in d[1:]:\n",
    "        ls = np.intersect1d(ls,new).tolist()\n",
    "    return ls\n",
    "\n",
    "\n",
    "def import_CsiPwr_data(directory):\n",
    "    \"\"\"\n",
    "    import all spectrogram (in pair) in the directory\n",
    "    \"\"\"\n",
    "    print(\"Importing Data \",end='')\n",
    "    data = {'X':{},'y':{}}\n",
    "    for label in os.listdir(directory):\n",
    "        pfiles = []\n",
    "        for modality in os.listdir(directory+'/'+label):\n",
    "            pfiles.append([f.split('.')[0] for f in os.listdir(directory+'/'+label+'/'+modality)])\n",
    "\n",
    "        print('>',end='')\n",
    "        common_files = intersect(pfiles)\n",
    "        \n",
    "        \n",
    "        for modality in os.listdir(directory+'/'+label):\n",
    "            files = [directory+'/'+label+'/'+modality+'/'+pfilename+'.csv' for pfilename in common_files]\n",
    "            X = import_spectrograms(files)\n",
    "            y = np.full(X.shape[0], label)\n",
    "            X[modality]\n",
    "        \n",
    "        # selcting available pairs\n",
    "        pfiles_csi = [f.split('.')[0] for f in os.listdir(directory+'/'+label+'/'+'csi')]\n",
    "        pfiles_pwr = [f.split('.')[0] for f in os.listdir(directory+'/'+label+'/'+'pwr')]\n",
    "        available_pairs = np.intersect1d(pfiles_csi,pfiles_pwr).tolist()\n",
    "        files_csi = [directory+'/'+label+'/'+'csi'+'/'+pfilename+'.csv' for pfilename in available_pairs]\n",
    "        files_pwr = [directory+'/'+label+'/'+'pwr'+'/'+pfilename+'.csv' for pfilename in available_pairs]\n",
    "        # importing\n",
    "        X1 = import_spectrograms(files_csi)\n",
    "        X2 = import_spectrograms(files_pwr)\n",
    "        y = np.full(X1.shape[0], label)\n",
    "        assert X1.shape[0] == X2.shape[0]\n",
    "        data['X1'].append(X1)\n",
    "        data['X2'].append(X2)\n",
    "        data['y'].append(y)\n",
    "    print(\" Complete\")\n",
    "    return np.concatenate(data['X1']), np.concatenate(data['X2']), np.concatenate(data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.transformation import label_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(['car','cat','cat','cow','cow','cow'])\n",
    "arr,lb = label_encode(arr)\n",
    "class_weight = torch.FloatTensor([1-w for w in pd.Series(arr).value_counts(normalize=True).sort_index().tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8333, 0.6667, 0.5000])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['car', 'cat', 'cow'], dtype='<U3')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1024)\n",
    "torch.manual_seed(1024)\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = DEVICE\n",
    "PATH = '.'\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "torch.cuda.set_device(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRC = 'E:/external_data/Experiment4/Spectrogram_data_csv_files/CSI_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import prepare_double_source,prepare_single_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ , train_loader, test_loader, lb, weight = prepare_double_source(directory=DIRC,\n",
    "                                                          modality='single',\n",
    "                                                          axis=1,\n",
    "                                                          train_size=0.8,\n",
    "                                                          joint='joint',\n",
    "                                                          p=None,\n",
    "                                                          sampling='weight',\n",
    "                                                          batch_size=64,\n",
    "                                                          num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Data >>>>>> Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-23 14:39:21,574 - [INFO] - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (760, 1, 65, 501) \ty_train:  (760,) \tX_test:  (190, 1, 65, 501) \ty_test:  (190,)\n",
      "class:  ['lay' 'picking' 'sit' 'stand_s' 'walking' 'waving']\n",
      "class_size:  tensor([0.0526, 0.1303, 0.1197, 0.1408, 0.3855, 0.1711])\n"
     ]
    }
   ],
   "source": [
    "train_loader,test_loader,lb,class_weight = prepare_single_source(directory=DIRC,axis=3,train_size=0.8,sampling='weight',batch_size=64,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [64, 128, 61, 497]           3,328\n",
      "       BatchNorm2d-2         [64, 128, 61, 497]             256\n",
      "              ReLU-3         [64, 128, 61, 497]               0\n",
      "         MaxPool2d-4         [64, 128, 30, 248]               0\n",
      "            Conv2d-5         [64, 128, 14, 123]         262,272\n",
      "       BatchNorm2d-6         [64, 128, 14, 123]             256\n",
      "              ReLU-7         [64, 128, 14, 123]               0\n",
      "         MaxPool2d-8           [64, 128, 7, 61]               0\n",
      "            Conv2d-9           [64, 128, 2, 20]         147,584\n",
      "           Lambda-10           [64, 128, 2, 20]               0\n",
      "             Tanh-11           [64, 128, 2, 20]               0\n",
      "        MaxPool2d-12           [64, 128, 1, 10]               0\n",
      "          Encoder-13                 [64, 1280]               0\n",
      "           Linear-14                  [64, 128]         163,968\n",
      "           Linear-15                    [64, 6]             774\n",
      "       Classifier-16                    [64, 6]               0\n",
      "================================================================\n",
      "Total params: 578,438\n",
      "Trainable params: 578,438\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 7.95\n",
      "Forward/backward pass size (MB): 6507.82\n",
      "Params size (MB): 2.21\n",
      "Estimated Total Size (MB): 6517.98\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from models.utils import Lambda,Classifier,ED_module\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Three layer Encoder for spectrogram (1,65,65), 3 layer\n",
    "    \"\"\"\n",
    "    def __init__(self,num_filters):\n",
    "        super(Encoder, self).__init__()\n",
    "        l1,l2,l3 = num_filters\n",
    "        ### 1st ###\n",
    "        self.conv1 = nn.Conv2d(1,l1,kernel_size=5,stride=1)\n",
    "        self.norm1 = nn.BatchNorm2d(l1) # nn.BatchNorm2d()\n",
    "        self.actv1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        ### 2nd ###\n",
    "        self.conv2 = nn.Conv2d(l1,l2,kernel_size=4,stride=2)\n",
    "        self.norm2 = nn.BatchNorm2d(l2)\n",
    "        self.actv2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        ### 3rd ###\n",
    "        self.conv3 = nn.Conv2d(l2,l3,kernel_size=3,stride=3)\n",
    "        self.norm3 = Lambda(lambda x:x)\n",
    "        self.actv3 = nn.Tanh()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2,2))\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = self.pool1(self.actv1(self.norm1(self.conv1(X))))\n",
    "        X = self.pool2(self.actv2(self.norm2(self.conv2(X))))\n",
    "        X = self.pool3(self.actv3(self.norm3(self.conv3(X))))\n",
    "        X = torch.flatten(X, 1)\n",
    "        # print(X.shape)\n",
    "        return X\n",
    "\n",
    "    \n",
    "def create_model():\n",
    "    out = 128\n",
    "    enc = Encoder([128,128,out]) # 1440\n",
    "    # summary(enc,(1,65,501),batch_size=64)\n",
    "    dec = Classifier(10*out,128,6)\n",
    "    model = ED_module(enc,dec)\n",
    "    return model\n",
    "\n",
    "model = create_model().to(DEVICE)\n",
    "summary(model,(1,65,501),batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=class_weight).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(list(model.parameters()), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "Epoch 1: >"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 234.00 MiB (GPU 0; 4.00 GiB total capacity; 2.79 GiB already allocated; 12.84 MiB free; 2.81 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-3e742e9e5cf6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                       \u001b[0mtest_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                       \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                       regularize = True)\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Creator\\Script\\Python\\Project\\irs_toolbox\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, criterion, optimizer, end, start, test_loader, device, regularize, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\">\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Creator\\Script\\Python\\Project\\irs_toolbox\\models\\utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-102-11d4ed9a29dc>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\pooling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    153\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0;32m    154\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m                             self.return_indices)\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     return torch.max_pool2d(\n\u001b[1;32m--> 586\u001b[1;33m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m max_pool2d = boolean_dispatch(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 234.00 MiB (GPU 0; 4.00 GiB total capacity; 2.79 GiB already allocated; 12.84 MiB free; 2.81 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "from train import train\n",
    "\n",
    "model, record = train(model=model,\n",
    "                      train_loader=train_loader,\n",
    "                      criterion=criterion,\n",
    "                      optimizer=optimizer,\n",
    "                      end=NUM_EPOCHS,\n",
    "                      start = 1,\n",
    "                      test_loader = test_loader,\n",
    "                      device = DEVICE,\n",
    "                      regularize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import evaluation,record_log,save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0         1          2          3          4          5  \\\n",
      "precision  0.750   0.62069   0.500000   0.714286   0.863014   0.860465   \n",
      "recall     0.375   0.62069   0.526316   0.555556   0.954545   0.902439   \n",
      "f1-score   0.500   0.62069   0.512821   0.625000   0.906475   0.880952   \n",
      "support    8.000  29.00000  19.000000  27.000000  66.000000  41.000000   \n",
      "\n",
      "           accuracy   macro avg  weighted avg  \n",
      "precision  0.768421    0.718076      0.763283  \n",
      "recall     0.768421    0.655758      0.768421  \n",
      "f1-score   0.768421    0.674323      0.760868  \n",
      "support    0.768421  190.000000    190.000000  \n"
     ]
    }
   ],
   "source": [
    "cmtx,cls = evaluation(model,test_loader,label_encoder=lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoint in : ./models/saved_models/Trainmode_normal_Network_shallowv2_Data_exp4nuc1_checkpoint_100__2021_02_23_15_28\n"
     ]
    }
   ],
   "source": [
    "MAIN_NAME = 'Trainmode_normal_Network_shallowv2_Data_exp4nuc1'\n",
    "record_log(MAIN_NAME,NUM_EPOCHS,record,cmtx=cmtx,cls=cls)\n",
    "save(MAIN_NAME,model,optimizer,NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
