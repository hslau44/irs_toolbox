{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "# import glob\n",
    "# import seaborn as sn  # for heatmaps\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_sepctrograms(path,columns=columns):\n",
    "    data = dict()\n",
    "    for label in os.listdir(path):\n",
    "        data[label] = dict()\n",
    "        for f in listdir(path+'/'+label):\n",
    "            user = f.split('.')[0].split('_')[1]\n",
    "            df = pd.read_csv(path+'/'+label+'/'+f, names=columns)\n",
    "            if user not in data[label]:\n",
    "                data[label][user] = []\n",
    "            data[label][user].append(df)\n",
    "        print(label)\n",
    "    return data\n",
    "\n",
    "# path = \"E:/external_data/Experiment2/spectrogram_data_by_activity_csv\"\n",
    "# data = import_sepctrograms(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lay\n",
      "picking\n",
      "sit\n",
      "walking\n",
      "waving\n",
      "stand_l\n",
      "stand_s\n"
     ]
    }
   ],
   "source": [
    "columns = [f\"col_{i+1}\" for i in range(501)]\n",
    "window_size=65\n",
    "slide_size=30\n",
    "dirc = 'E://external_data/Experiment4/Spectrogram_data_csv_files/CSI_data'\n",
    "\n",
    "X,y  = import_data(dirc,columns=columns,window_size=window_size,slide_size=slide_size) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cross_validation(item_func,X,y,n_splits):\n",
    "\n",
    "    acc_score = []\n",
    "\n",
    "    kf = KFold(n_splits)\n",
    "    \n",
    "    for train_index , test_index in kf.split(X):\n",
    "        X_train , X_test = X[train_index], X[test_index]\n",
    "        y_train , y_test = y[train_index], y[test_index]\n",
    "        train_loader, test_loader = create_dataloader(X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        # create model \n",
    "        model,optimizer,criterion = item_func()\n",
    "        \n",
    "        # train model\n",
    "        model.fit(X_train,y_train)\n",
    "        pred_values = model.predict(X_test)\n",
    "        \n",
    "        # evaluate\n",
    "        acc = accuracy_score(pred_values , y_test)\n",
    "        acc_score.append(acc)\n",
    "\n",
    "    avg_acc_score = sum(acc_score)/k\n",
    "\n",
    "    print('accuracy of each fold - {}'.format(acc_score))\n",
    "    print('Avg accuracy : {}'.format(avg_acc_score))\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(p1,p2,t=1):\n",
    "    val = p1.dot(p2.transpose())/t\n",
    "    val = np.exp(val)\n",
    "    val = -np.log(np.diag(val)/np.sum(val,axis=1))\n",
    "    return val\n",
    "\n",
    "p1 = np.array([\n",
    " [ 0.70374682, -0.18682394, -0.68544673],\n",
    " [ 0.15465702,  0.32303224,  0.93366556],\n",
    " [ 0.53043332, -0.83523217, -0.14500935],\n",
    " [ 0.68285685, -0.73054075,  0.00409143],\n",
    " [ 0.76652431,  0.61500886,  0.18494479]])\n",
    "\n",
    "p2 = p1 + 0.1*np.random.random(p1.shape)\n",
    "\n",
    "# contrastive_loss(p1,p2,0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def contrastive_loss(z1,z2,t=1):\n",
    "    \"\"\"\n",
    "    One to N\n",
    "    \"\"\"\n",
    "    a = torch.mm(z1,z2.transpose(0,1))\n",
    "    b = torch.norm(z1,dim=1)*torch.norm(z2,dim=1)\n",
    "    sim_mat = torch.div(a,b)\n",
    "    mask = torch.ones_like(sim_mat,dtype=bool).fill_diagonal_(0)\n",
    "    pos = torch.diag(sim_mat).reshape(-1,1)\n",
    "    neg = sim_mat[mask].reshape(pos.shape[0],-1)\n",
    "    logits = torch.cat((pos, neg), dim=1)\n",
    "    labels = torch.zeros(pos.shape[0]).long()\n",
    "    loss = torch.nn.CrossEntropyLoss()(logits,labels)\n",
    "    return loss\n",
    "\n",
    "z1 = torch.tensor(p1)\n",
    "z2 = torch.tensor(p2)\n",
    "z3 = torch.zeros_like(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# z = torch.cat((z1,z2))\n",
    "# a = torch.mm(z,z.transpose(0,1))\n",
    "# b = torch.norm(z,dim=1)*torch.norm(z,dim=1)\n",
    "# sim_mat = torch.div(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 1, 2, 2)\n",
      "tensor([[ 0.7037, -0.1868, -0.6854],\n",
      "        [ 0.1547,  0.3230,  0.9337],\n",
      "        [ 0.5304, -0.8352, -0.1450],\n",
      "        [ 0.6829, -0.7305,  0.0041],\n",
      "        [ 0.7665,  0.6150,  0.1849]], dtype=torch.float64) \n",
      " tensor([[ 0.7574, -0.1747, -0.6278],\n",
      "        [ 0.2005,  0.3507,  1.0219],\n",
      "        [ 0.5990, -0.7372, -0.1021],\n",
      "        [ 0.7229, -0.6615,  0.0377],\n",
      "        [ 0.8089,  0.6713,  0.2799]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9960, -0.6249,  0.6292,  0.6065,  0.2519],\n",
       "        [-0.5255,  1.0984, -0.2408, -0.0667,  0.6033],\n",
       "        [ 0.6387, -0.3347,  0.9482,  0.9305, -0.1722],\n",
       "        [ 0.6423, -0.1151,  0.9471,  0.9771,  0.0631],\n",
       "        [ 0.3570,  0.5583, -0.0131,  0.1543,  1.0846]], dtype=torch.float64)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((0,1,1,2,2))\n",
    "print(z1,'\\n',z2)\n",
    "torch.mm(z1,z2.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses import SupConLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "lb = np.array([1,2,1,2,1])\n",
    "# lb =  OneHotEncoder().fit_transform(lb.reshape(-1,1)).toarray()\n",
    "print(lb)\n",
    "lb = torch.tensor(lb)\n",
    "\n",
    "pair1 = torch.cat((z1.unsqueeze(1),z1.unsqueeze(1)),dim=1)\n",
    "pair2 = torch.cat((z1.unsqueeze(1),z2.unsqueeze(1)),dim=1)\n",
    "pair3 = torch.cat((z3.unsqueeze(1),z3.unsqueeze(1)),dim=1)\n",
    "pair4 = torch.cat((z1.unsqueeze(1),z3.unsqueeze(1)),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.3098, dtype=torch.float64)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supcon = SupConLoss(temperature=0.01,stack=True)\n",
    "# z1 = nn.functional.normalize(z1,dim=1)\n",
    "supcon.forward(z2,labels=lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupConLoss(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    Supervised Contrastive Learning: https://arxiv.org/pdf/2004.11362.pdf.\n",
    "    It also supports the unsupervised contrastive loss in SimCLR\n",
    "\n",
    "    origin: https://github.com/HobbitLong/SupContrast.git\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, temperature=0.07, contrast_mode='all',\n",
    "                 base_temperature=0.07,stack=True):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "        self.stack = stack\n",
    "\n",
    "    def forward(self, features, labels=None, mask=None):\n",
    "        \"\"\"Compute loss for model. If both `labels` and `mask` are None,\n",
    "        it degenerates to SimCLR unsupervised loss:\n",
    "        https://arxiv.org/pdf/2002.05709.pdf\n",
    "        Args:\n",
    "            features: hidden vector of shape [bsz, n_views, ...].\n",
    "            labels: ground truth of shape [bsz].\n",
    "            mask: contrastive mask of shape [bsz, bsz], mask_{i,j}=1 if sample j\n",
    "                has the same class as sample i. Can be asymmetric.\n",
    "        Returns:\n",
    "            A loss scalar.\n",
    "        \"\"\"\n",
    "        device = (torch.device('cuda')\n",
    "                  if features.is_cuda\n",
    "                  else torch.device('cpu'))\n",
    "        \n",
    "        if self.stack == True:\n",
    "            features = features.unsqueeze(1)\n",
    "            features = torch.cat((features,features),dim=1)\n",
    "            \n",
    "        \n",
    "\n",
    "        if len(features.shape) < 3:\n",
    "            raise ValueError('`features` needs to be [bsz, n_views, ...],'\n",
    "                             'at least 3 dimensions are required')\n",
    "        if len(features.shape) > 3:\n",
    "            features = features.view(features.shape[0], features.shape[1], -1)\n",
    "\n",
    "        batch_size = features.shape[0]\n",
    "        if labels is not None and mask is not None:\n",
    "            raise ValueError('Cannot define both `labels` and `mask`')\n",
    "        elif labels is None and mask is None:\n",
    "            mask = torch.eye(batch_size, dtype=torch.float32).to(device)\n",
    "        elif labels is not None:\n",
    "            labels = labels.contiguous().view(-1, 1)\n",
    "            if labels.shape[0] != batch_size:\n",
    "                raise ValueError('Num of labels does not match num of features')\n",
    "            mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        else:\n",
    "            mask = mask.float().to(device)\n",
    "\n",
    "        contrast_count = features.shape[1]\n",
    "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        if self.contrast_mode == 'one':\n",
    "            anchor_feature = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == 'all':\n",
    "            anchor_feature = contrast_feature\n",
    "            anchor_count = contrast_count\n",
    "        else:\n",
    "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
    "\n",
    "        # compute logits\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(anchor_feature, contrast_feature.T),\n",
    "            self.temperature)\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "        # tile mask\n",
    "        mask = mask.repeat(anchor_count, contrast_count)\n",
    "        # mask-out self-contrast cases\n",
    "        logits_mask = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "            0\n",
    "        )\n",
    "        mask = mask * logits_mask\n",
    "\n",
    "        # compute log_prob\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "\n",
    "        # compute mean of log-likelihood over positive\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n",
    "\n",
    "        # loss\n",
    "        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n",
    "        loss = loss.view(anchor_count, batch_size).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
