{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import glob\n",
    "# import seaborn as sn  # for heatmaps\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_sepctrograms(path,columns=columns):\n",
    "    data = dict()\n",
    "    for label in os.listdir(path):\n",
    "        data[label] = dict()\n",
    "        for f in listdir(path+'/'+label):\n",
    "            user = f.split('.')[0].split('_')[1]\n",
    "            df = pd.read_csv(path+'/'+label+'/'+f, names=columns)\n",
    "            if user not in data[label]:\n",
    "                data[label][user] = []\n",
    "            data[label][user].append(df)\n",
    "        print(label)\n",
    "    return data\n",
    "\n",
    "# path = \"E:/external_data/Experiment2/spectrogram_data_by_activity_csv\"\n",
    "# data = import_sepctrograms(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kneel\n",
      "lie\n",
      "pickup\n",
      "sit\n",
      "stand\n",
      "standff\n",
      "walk\n"
     ]
    }
   ],
   "source": [
    "columns = [f\"col_{i+1}\" for i in range(501)]\n",
    "window_size=30\n",
    "slide_size=30\n",
    "dirc = 'E://external_data/Experiment2/spectrogram_data_by_activity_csv'\n",
    "\n",
    "X,y  = import_data(dirc,columns=columns,window_size=window_size,slide_size=slide_size) # \n",
    "y,lb = label_encode(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "\n",
    "def create_dataloaders(X_train, y_train, X_test, y_test, train_batch_sizes=64, test_batch_sizes=200):\n",
    "    traindataset = TensorDataset(Tensor(X_train),Tensor(y_train).long())\n",
    "    testdataset = TensorDataset(Tensor(X_test), Tensor(y_test).long())\n",
    "    train_loader = DataLoader(traindataset, batch_size=train_batch_sizes, shuffle=True, num_workers=1, drop_last=True)\n",
    "    test_loader = DataLoader(testdataset, batch_size=test_batch_sizes, shuffle=True, num_workers=1)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "train_loader, test_loader = create_dataloaders(X_train, y_train, X_test, y_test, train_batch_sizes=128, test_batch_sizes=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cross_validation(item_func,X,y,n_splits):\n",
    "\n",
    "    acc_score = []\n",
    "\n",
    "    kf = KFold(n_splits)\n",
    "    \n",
    "    for train_index , test_index in kf.split(X):\n",
    "        X_train , X_test = X[train_index], X[test_index]\n",
    "        y_train , y_test = y[train_index], y[test_index]\n",
    "        train_loader, test_loader = create_dataloader(X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        # create model \n",
    "        model,optimizer,criterion = item_func()\n",
    "        \n",
    "        # train model\n",
    "        model.fit(X_train,y_train)\n",
    "        pred_values = model.predict(X_test)\n",
    "        \n",
    "        # evaluate\n",
    "        acc = accuracy_score(pred_values , y_test)\n",
    "        acc_score.append(acc)\n",
    "\n",
    "    avg_acc_score = sum(acc_score)/k\n",
    "\n",
    "    print('accuracy of each fold - {}'.format(acc_score))\n",
    "    print('Avg accuracy : {}'.format(avg_acc_score))\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
