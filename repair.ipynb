{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "# import glob\n",
    "# import seaborn as sn  # for heatmaps\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_sepctrograms(path,columns=columns):\n",
    "    data = dict()\n",
    "    for label in os.listdir(path):\n",
    "        data[label] = dict()\n",
    "        for f in listdir(path+'/'+label):\n",
    "            user = f.split('.')[0].split('_')[1]\n",
    "            df = pd.read_csv(path+'/'+label+'/'+f, names=columns)\n",
    "            if user not in data[label]:\n",
    "                data[label][user] = []\n",
    "            data[label][user].append(df)\n",
    "        print(label)\n",
    "    return data\n",
    "\n",
    "# path = \"E:/external_data/Experiment2/spectrogram_data_by_activity_csv\"\n",
    "# data = import_sepctrograms(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lay\n",
      "picking\n",
      "sit\n",
      "walking\n",
      "waving\n",
      "stand_l\n",
      "stand_s\n"
     ]
    }
   ],
   "source": [
    "columns = [f\"col_{i+1}\" for i in range(501)]\n",
    "window_size=65\n",
    "slide_size=30\n",
    "dirc = 'E://external_data/Experiment4/Spectrogram_data_csv_files/CSI_data'\n",
    "\n",
    "X,y  = import_data(dirc,columns=columns,window_size=window_size,slide_size=slide_size) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cross_validation(item_func,X,y,n_splits):\n",
    "\n",
    "    acc_score = []\n",
    "\n",
    "    kf = KFold(n_splits)\n",
    "    \n",
    "    for train_index , test_index in kf.split(X):\n",
    "        X_train , X_test = X[train_index], X[test_index]\n",
    "        y_train , y_test = y[train_index], y[test_index]\n",
    "        train_loader, test_loader = create_dataloader(X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        # create model \n",
    "        model,optimizer,criterion = item_func()\n",
    "        \n",
    "        # train model\n",
    "        model.fit(X_train,y_train)\n",
    "        pred_values = model.predict(X_test)\n",
    "        \n",
    "        # evaluate\n",
    "        acc = accuracy_score(pred_values , y_test)\n",
    "        acc_score.append(acc)\n",
    "\n",
    "    avg_acc_score = sum(acc_score)/k\n",
    "\n",
    "    print('accuracy of each fold - {}'.format(acc_score))\n",
    "    print('Avg accuracy : {}'.format(avg_acc_score))\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(p1,p2,t=1):\n",
    "    val = p1.dot(p2.transpose())/t\n",
    "    val = np.exp(val)\n",
    "    val = -np.log(np.diag(val)/np.sum(val,axis=1))\n",
    "    return val\n",
    "\n",
    "p1 = np.array([\n",
    " [ 0.70374682, -0.18682394, -0.68544673],\n",
    " [ 0.15465702,  0.32303224,  0.93366556],\n",
    " [ 0.53043332, -0.83523217, -0.14500935],\n",
    " [ 0.68285685, -0.73054075,  0.00409143],\n",
    " [ 0.76652431,  0.61500886,  0.18494479]])\n",
    "\n",
    "p2 = p1 + 0.1*np.random.random(p1.shape)\n",
    "\n",
    "# contrastive_loss(p1,p2,0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def contrastive_loss(z1,z2,t=1):\n",
    "    \"\"\"\n",
    "    One to N\n",
    "    \"\"\"\n",
    "    a = torch.mm(z1,z2.transpose(0,1))\n",
    "    b = torch.norm(z1,dim=1)*torch.norm(z2,dim=1)\n",
    "    sim_mat = torch.div(a,b)\n",
    "    mask = torch.ones_like(sim_mat,dtype=bool).fill_diagonal_(0)\n",
    "    pos = torch.diag(sim_mat).reshape(-1,1)\n",
    "    neg = sim_mat[mask].reshape(pos.shape[0],-1)\n",
    "    logits = torch.cat((pos, neg), dim=1)\n",
    "    labels = torch.zeros(pos.shape[0]).long()\n",
    "    loss = torch.nn.CrossEntropyLoss()(logits,labels)\n",
    "    return loss\n",
    "\n",
    "z1 = torch.tensor(p1)\n",
    "z2 = torch.tensor(p2)\n",
    "z3 = torch.zeros_like(z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUC pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchsummary import summary\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contrastive_learning import switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contrastive_learning import prepare_dataloader_pairdata,switch, create_finetune_model\n",
    "from models.baseline import Encoder_F as Encoder\n",
    "from train import train as finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Data >>>>>> Complete\n",
      "X_train:  (1150, 1, 65, 501) y_train:  (1150,) X_test:  (288, 1, 65, 501) y_test:  (288,)\n",
      "GPU\n",
      "Start Training\n",
      "Epoch 1: >>>>>>>>>>>>>>>>> loss: 1.091564416885376 \n",
      "Epoch 2: >>>>>>>>>>>>>>>>> loss: 1.021856665611267 \n",
      "Epoch 3: >>>>>>>>>>>>>>>>> loss: 0.9995803833007812 \n",
      "Epoch 4: >>>>>>>>>>>>>>>>> loss: 0.867952823638916 \n",
      "Epoch 5: >>>>>>>>>>>>>>>>> loss: 0.9036494493484497 \n",
      "Epoch 6: >>>>>>>>>>>>>>>>> loss: 0.8991919159889221 \n",
      "Epoch 7: >>>>>>>>>>>>>>>>> loss: 0.6593881249427795 \n",
      "Epoch 8: >>>>>>>>>>>>>>>>> loss: 0.5391482710838318 \n",
      "Epoch 9: >>>>>>>>>>>>>>>>> loss: 0.4440034031867981 \n",
      "Epoch 10: >>>>>>>>>>>>>>>>> loss: 0.320463091135025  accuracy: 0.7083333333333334\n",
      "Epoch 11: >>>>>>>>>>>>>>>>> loss: 0.2834102511405945 \n",
      "Epoch 12: >>>>>>>>>>>>>>>>> loss: 0.29427874088287354 \n",
      "Epoch 13: >>>>>>>>>>>>>>>>> loss: 0.18920671939849854 \n",
      "Epoch 14: >>>>>>>>>>>>>>>>> loss: 0.11102481186389923 \n",
      "Epoch 15: >>>>>>>>>>>>>>>>> loss: 0.17029434442520142 \n",
      "Epoch 16: >>>>>>>>>>>>>>>>> loss: 0.09413407742977142 \n",
      "Epoch 17: >>>>>>>>>>>>>>>>> loss: 0.01819976605474949 \n",
      "Epoch 18: >>>>>>>>>>>>>>>>> loss: 0.08840031921863556 \n",
      "Epoch 19: >>>>>>>>>>>>>>>>> loss: 0.009771454147994518 \n",
      "Epoch 20: >>>>>>>>>>>>>>>>> loss: 0.004506246652454138  accuracy: 0.7152777777777778\n",
      "Epoch 21: >>>>>>>>>>>>>>>>> loss: 0.0031139161437749863 \n",
      "Epoch 22: >>>>>>>>>>>>>>>>> loss: 0.001809916109777987 \n",
      "Epoch 23: >>>>>>>>>>>>>>>>> loss: 0.012424413114786148 \n",
      "Epoch 24: >>>>>>>>>>>>>>>>> loss: 0.0010266188764944673 \n",
      "Epoch 25: >>>>>>>>>>>>>>>>> loss: 0.0029315229039639235 \n",
      "Epoch 26: >>>>>>>>>>>>>>>>> loss: 0.0028079748153686523 \n",
      "Epoch 27: >>>>>>>>>>>>>>>>> loss: 0.0014831727603450418 \n",
      "Epoch 28: >>>>>>>>>>>>>>>>> loss: 0.0013924235245212913 \n",
      "Epoch 29: >>>>>>>>>>>>>>>>> loss: 0.0011244864435866475 \n",
      "Epoch 30: >>>>>>>>>>>>>>>>> loss: 0.001273690490052104  accuracy: 0.7083333333333334\n",
      "Epoch 31: >>>>>>>>>>>>>>>>> loss: 0.0009748732554726303 \n",
      "Epoch 32: >>>>>>>>>>>>>>>>> loss: 0.0003621564246714115 \n",
      "Epoch 33: >>>>>>>>>>>>>>>>> loss: 0.0005778385675512254 \n",
      "Epoch 34: >>>>>>>>>>>>>>>>> loss: 0.002108353888615966 \n",
      "Epoch 35: >>>>>>>>>>>>>>>>> loss: 0.00044093525502830744 \n",
      "Epoch 36: >>>>>>>>>>>>>>>>> loss: 0.0005110969650559127 \n",
      "Epoch 37: >>>>>>>>>>>>>>>>> loss: 0.0006137309246696532 \n",
      "Epoch 38: >>>>>>>>>>>>>>>>> loss: 0.0004977156058885157 \n",
      "Epoch 39: >>>>>>>>>>>>>>>>> loss: 0.0005276466836221516 \n",
      "Epoch 40: >>>>>>>>>>>>>>>>> loss: 0.00038292663521133363  accuracy: 0.7048611111111112\n",
      "Epoch 41: >>>>>>>>>>>>>>>>> loss: 0.0003151246637571603 \n",
      "Epoch 42: >>>>>>>>>>>>>>>>> loss: 0.004071719944477081 \n",
      "Epoch 43: >>>>>>>>>>>>>>>>> loss: 0.0006042925524525344 \n",
      "Epoch 44: >>>>>>>>>>>>>>>>> loss: 0.0005579903954640031 \n",
      "Epoch 45: >>>>>>>>>>>>>>>>> loss: 0.00039240819751285017 \n",
      "Epoch 46: >>>>>>>>>>>>>>>>> loss: 0.0033879424445331097 \n",
      "Epoch 47: >>>>>>>>>>>>>>>>> loss: 0.0002635273558553308 \n",
      "Epoch 48: >>>>>>>>>>>>>>>>> loss: 0.00024130352539941669 \n",
      "Epoch 49: >>>>>>>>>>>>>>>>> loss: 0.00018433814693707973 \n",
      "Epoch 50: >>>>>>>>>>>>>>>>> loss: 0.00026248805806972086  accuracy: 0.6944444444444444\n",
      "Epoch 51: >>>>>>>>>>>>>>>>> loss: 0.00022842196631245315 \n",
      "Epoch 52: >>>>>>>>>>>>>>>>> loss: 0.00018699538486544043 \n",
      "Epoch 53: >>>>>>>>>>>>>>>>> loss: 0.0008269522804766893 \n",
      "Epoch 54: >>>>>>>>>>>>>>>>> loss: 0.00047919119242578745 \n",
      "Epoch 55: >>>>>>>>>>>>>>>>> loss: 0.0002489075995981693 \n",
      "Epoch 56: >>>>>>>>>>>>>>>>> loss: 0.0003686106647364795 \n",
      "Epoch 57: >>>>>>>>>>>>>>>>> loss: 0.0001719772262731567 \n",
      "Epoch 58: >>>>>>>>>>>>>>>>> loss: 0.00017822583322413266 \n",
      "Epoch 59: >>>>>>>>>>>>>>>>> loss: 0.00010816245776368305 \n",
      "Epoch 60: >>>>>>>>>>>>>>>>> loss: 0.00013480101188179106  accuracy: 0.7048611111111112\n",
      "Epoch 61: >>>>>>>>>>>>>>>>> loss: 0.00023542797134723514 \n",
      "Epoch 62: >>>>>>>>>>>>>>>>> loss: 0.00015036620607133955 \n",
      "Epoch 63: >>>>>>>>>>>>>>>>> loss: 7.448365067830309e-05 \n",
      "Epoch 64: >>>>>>>>>>>>>>>>> loss: 0.00021881831344217062 \n",
      "Epoch 65: >>>>>>>>>>>>>>>>> loss: 0.0001748495560605079 \n",
      "Epoch 66: >>>>>>>>>>>>>>>>> loss: 0.00010927770199486986 \n",
      "Epoch 67: >>>>>>>>>>>>>>>>> loss: 0.00017181134899146855 \n",
      "Epoch 68: >>>>>>>>>>>>>>>>> loss: 0.0001691696816124022 \n",
      "Epoch 69: >>>>>>>>>>>>>>>>> loss: 0.00018329352315049618 \n",
      "Epoch 70: >>>>>>>>>>>>>>>>> loss: 0.0002023845590883866  accuracy: 0.7083333333333334\n",
      "Epoch 71: >>>>>>>>>>>>>>>>> loss: 0.00016305242024827749 \n",
      "Epoch 72: >>>>>>>>>>>>>>>>> loss: 7.537339843111113e-05 \n",
      "Epoch 73: >>>>>>>>>>>>>>>>> loss: 0.00014003828982822597 \n",
      "Epoch 74: >>>>>>>>>>>>>>>>> loss: 0.00015556358266621828 \n",
      "Epoch 75: >>>>>>>>>>>>>>>>> loss: 9.899752330966294e-05 \n",
      "Epoch 76: >>>>>>>>>>>>>>>>> loss: 0.00013102621596772224 \n",
      "Epoch 77: >>>>>>>>>>>>>>>>> loss: 0.00016376885469071567 \n",
      "Epoch 78: >>>>>>>>>>>>>>>>> loss: 0.00032525756978429854 \n",
      "Epoch 79: >>>>>>>>>>>>>>>>> loss: 0.00012813073408324271 \n",
      "Epoch 80: >>>>>>>>>>>>>>>>> loss: 7.990717858774588e-05  accuracy: 0.6979166666666666\n",
      "Epoch 81: >>>>>>>>>>>>>>>>> loss: 5.368997881305404e-05 \n",
      "Epoch 82: >>>>>>>>>>>>>>>>> loss: 0.00011138081754324958 \n",
      "Epoch 83: >>>>>>>>>>>>>>>>> loss: 0.00023742008488625288 \n",
      "Epoch 84: >>>>>>>>>>>>>>>>> loss: 0.0004299336578696966 \n",
      "Epoch 85: >>>>>>>>>>>>>>>>> loss: 0.00023088995658326894 \n",
      "Epoch 86: >>>>>>>>>>>>>>>>> loss: 0.00012774979404639453 \n",
      "Epoch 87: >>>>>>>>>>>>>>>>> loss: 0.00018766438006423414 \n",
      "Epoch 88: >>>>>>>>>>>>>>>>> loss: 0.00013392834807746112 \n",
      "Epoch 89: >>>>>>>>>>>>>>>>> loss: 7.032010762486607e-05 \n",
      "Epoch 90: >>>>>>>>>>>>>>>>> loss: 0.00020771902927663177  accuracy: 0.7048611111111112\n",
      "Epoch 91: >>>>>>>>>>>>>>>>> loss: 6.123500497778878e-05 \n",
      "Epoch 92: >>>>>>>>>>>>>>>>> loss: 5.3612915507983416e-05 \n",
      "Epoch 93: >>>>>>>>>>>>>>>>> loss: 8.385671389987692e-05 \n",
      "Epoch 94: >>>>>>>>>>>>>>>>> loss: 9.020475408760831e-05 \n",
      "Epoch 95: >>>>>>>>>>>>>>>>> loss: 4.0382001316174865e-05 \n",
      "Epoch 96: >>>>>>>>>>>>>>>>> loss: 5.195732228457928e-05 \n",
      "Epoch 97: >>>>>>>>>>>>>>>>> loss: 9.49266177485697e-05 \n",
      "Epoch 98: >>>>>>>>>>>>>>>>> loss: 3.41935628966894e-05 \n",
      "Epoch 99: >>>>>>>>>>>>>>>>> loss: 3.2459331123391166e-05 \n",
      "Epoch 100: >>>>>>>>>>>>>>>>> loss: 7.602757250424474e-05  accuracy: 0.7118055555555556\n",
      "Epoch 101: >>>>>>>>>>>>>>>>> loss: 5.4653690312989056e-05 \n",
      "Epoch 102: >>>>>>>>>>>>>>>>> loss: 0.00040870773955248296 \n",
      "Epoch 103: >>>>>>>>>>>>>>>>> loss: 5.760981366620399e-05 \n",
      "Epoch 104: >>>>>>>>>>>>>>>>> loss: 4.508571873884648e-05 \n",
      "Epoch 105: >>>>>>>>>>>>>>>>> loss: 0.0001165749054052867 \n",
      "Epoch 106: >>>>>>>>>>>>>>>>> loss: 0.00019287929171696305 \n",
      "Epoch 107: >>>>>>>>>>>>>>>>> loss: 6.990435940679163e-05 \n",
      "Epoch 108: >>>>>>>>>>>>>>>>> loss: 1.72229265444912e-05 \n",
      "Epoch 109: >>>>>>>>>>>>>>>>> loss: 3.87448635592591e-05 \n",
      "Epoch 110: >>>>>>>>>>>>>>>>> loss: 4.803657066076994e-05  accuracy: 0.7083333333333334\n",
      "Epoch 111: >>>>>>>>>>>>>>>>> loss: 8.341614011442289e-05 \n",
      "Epoch 112: >>>>>>>>>>>>>>>>> loss: 0.00012816402886528522 \n",
      "Epoch 113: >>>>>>>>>>>>>>>>> loss: 6.829119229223579e-05 \n",
      "Epoch 114: >>>>>>>>>>>>>>>>> loss: 3.0937575502321124e-05 \n",
      "Epoch 115: >>>>>>>>>>>>>>>>> loss: 6.137074524303898e-05 \n",
      "Epoch 116: >>>>>>>>>>>>>>>>> loss: 3.9689315599389374e-05 \n",
      "Epoch 117: >>>>>>>>>>>>>>>>> loss: 0.00019327366317156702 \n",
      "Epoch 118: >>>>>>>>>>>>>>>>> loss: 4.783702388522215e-05 \n",
      "Epoch 119: >>>>>>>>>>>>>>>>> loss: 1.7323573047178797e-05 \n",
      "Epoch 120: >>>>>>>>>>>>>>>>> loss: 3.155773811158724e-05  accuracy: 0.7152777777777778\n",
      "Epoch 121: >>>>>>>>>>>>>>>>> loss: 7.411277329083532e-05 \n",
      "Epoch 122: >>>>>>>>>>>>>>>>> loss: 3.220262806280516e-05 \n",
      "Epoch 123: >>>>>>>>>>>>>>>>> loss: 1.7258120351471007e-05 \n",
      "Epoch 124: >>>>>>>>>>>>>>>>> loss: 9.676270565250888e-06 \n",
      "Epoch 125: >>>>>>>>>>>>>>>>> loss: 2.6578100005281158e-05 \n",
      "Epoch 126: >>>>>>>>>>>>>>>>> loss: 3.121590634691529e-05 \n",
      "Epoch 127: >>>>>>>>>>>>>>>>> loss: 1.8886088582803495e-05 \n",
      "Epoch 128: >>>>>>>>>>>>>>>>> loss: 6.772828055545688e-05 \n",
      "Epoch 129: >>>>>>>>>>>>>>>>> loss: 6.554571154993027e-05 \n",
      "Epoch 130: >>>>>>>>>>>>>>>>> loss: 2.06331296794815e-05  accuracy: 0.7118055555555556\n",
      "Epoch 131: >>>>>>>>>>>>>>>>> loss: 3.228145942557603e-05 \n",
      "Epoch 132: >>>>>>>>>>>>>>>>> loss: 2.551865327404812e-05 \n",
      "Epoch 133: >>>>>>>>>>>>>>>>> loss: 2.712004970817361e-05 \n",
      "Epoch 134: >>>>>>>>>>>>>>>>> loss: 4.9817510443972424e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135: >>>>>>>>>>>>>>>>> loss: 2.8398842914612032e-05 \n",
      "Epoch 136: >>>>>>>>>>>>>>>>> loss: 0.0001096694395528175 \n",
      "Epoch 137: >>>>>>>>>>>>>>>>> loss: 2.78602383332327e-05 \n",
      "Epoch 138: >>>>>>>>>>>>>>>>> loss: 8.912719931686297e-05 \n",
      "Epoch 139: >>>>>>>>>>>>>>>>> loss: 1.3180994987487793 \n",
      "Epoch 140: >>>>>>>>>>>>>>>>> loss: 0.5841369032859802  accuracy: 0.5972222222222222\n",
      "Epoch 141: >>>>>>>>>>>>>>>>> loss: 0.4636678993701935 \n",
      "Epoch 142: >>>>>>>>>>>>>>>>> loss: 0.4708331525325775 \n",
      "Epoch 143: >>>>>>>>>>>>>>>>> loss: 0.2505548298358917 \n",
      "Epoch 144: >>>>>>>>>>>>>>>>> loss: 0.13396959006786346 \n",
      "Epoch 145: >>>>>>>>>>>>>>>>> loss: 0.1133517473936081 \n",
      "Epoch 146: >>>>>>>>>>>>>>>>> loss: 0.020170116797089577 \n",
      "Epoch 147: >>>>>>>>>>>>>>>>> loss: 0.028636496514081955 \n",
      "Epoch 148: >>>>>>>>>>>>>>>>> loss: 0.02172926440834999 \n",
      "Epoch 149: >>>>>>>>>>>>>>>>> loss: 0.0051382011733949184 \n",
      "Epoch 150: >>>>>>>>>>>>>>>>> loss: 0.0030515873804688454  accuracy: 0.6875\n",
      "Epoch 151: >>>>>>>>>>>>>>>>> loss: 0.001516888034529984 \n",
      "Epoch 152: >>>>>>>>>>>>>>>>> loss: 0.0028792049270123243 \n",
      "Epoch 153: >>>>>>>>>>>>>>>>> loss: 0.000984364771284163 \n",
      "Epoch 154: >>>>>>>>>>>>>>>>> loss: 0.0007244268781505525 \n",
      "Epoch 155: >>>>>>>>>>>>>>>>> loss: 0.0008825937402434647 \n",
      "Epoch 156: >>>>>>>>>>>>>>>>> loss: 0.0006091013783589005 \n",
      "Epoch 157: >>>>>>>>>>>>>>>>> loss: 0.000636021897662431 \n",
      "Epoch 158: >>>>>>>>>>>>>>>>> loss: 0.002483431249856949 \n",
      "Epoch 159: >>>>>>>>>>>>>>>>> loss: 0.000752946303691715 \n",
      "Epoch 160: >>>>>>>>>>>>>>>>> loss: 0.00027356919599696994  accuracy: 0.7152777777777778\n",
      "Epoch 161: >>>>>>>>>>>>>>>>> loss: 0.00017395368195138872 \n",
      "Epoch 162: >>>>>>>>>>>>>>>>> loss: 0.0004894476151093841 \n",
      "Epoch 163: >>>>>>>>>>>>>>>>> loss: 0.000280409847619012 \n",
      "Epoch 164: >>>>>>>>>>>>>>>>> loss: 0.00019727008475456387 \n",
      "Epoch 165: >>>>>>>>>>>>>>>>> loss: 0.0002925603766925633 \n",
      "Epoch 166: >>>>>>>>>>>>>>>>> loss: 0.00018035402172245085 \n",
      "Epoch 167: >>>>>>>>>>>>>>>>> loss: 0.0007774263503961265 \n",
      "Epoch 168: >>>>>>>>>>>>>>>>> loss: 0.00028219420346431434 \n",
      "Epoch 169: >>>>>>>>>>>>>>>>> loss: 0.0002406554267508909 \n",
      "Epoch 170: >>>>>>>>>>>>>>>>> loss: 0.00014841684605926275  accuracy: 0.7013888888888888\n",
      "Epoch 171: >>>>>>>>>>>>>>>>> loss: 0.0003240108781028539 \n",
      "Epoch 172: >>>>>>>>>>>>>>>>> loss: 0.000219664114410989 \n",
      "Epoch 173: >>>>>>>>>>>>>>>>> loss: 0.0009000017307698727 \n",
      "Epoch 174: >>>>>>>>>>>>>>>>> loss: 0.00022595225891564041 \n",
      "Epoch 175: >>>>>>>>>>>>>>>>> loss: 0.00018408495816402137 \n",
      "Epoch 176: >>>>>>>>>>>>>>>>> loss: 0.0002504733274690807 \n",
      "Epoch 177: >>>>>>>>>>>>>>>>> loss: 0.00010975437908200547 \n",
      "Epoch 178: >>>>>>>>>>>>>>>>> loss: 0.0003207161498721689 \n",
      "Epoch 179: >>>>>>>>>>>>>>>>> loss: 0.0002651561517268419 \n",
      "Epoch 180: >>>>>>>>>>>>>>>>> loss: 0.00012766521831508726  accuracy: 0.7083333333333334\n",
      "Epoch 181: >>>>>>>>>>>>>>>>> loss: 0.00017284211935475469 \n",
      "Epoch 182: >>>>>>>>>>>>>>>>> loss: 0.00011954939691349864 \n",
      "Epoch 183: >>>>>>>>>>>>>>>>> loss: 9.51601323322393e-05 \n",
      "Epoch 184: >>>>>>>>>>>>>>>>> loss: 0.0003143646172247827 \n",
      "Epoch 185: >>>>>>>>>>>>>>>>> loss: 0.00039330177241936326 \n",
      "Epoch 186: >>>>>>>>>>>>>>>>> loss: 0.00015238542982842773 \n",
      "Epoch 187: >>>>>>>>>>>>>>>>> loss: 5.385895929066464e-05 \n",
      "Epoch 188: >>>>>>>>>>>>>>>>> loss: 0.00033943852758966386 \n",
      "Epoch 189: >>>>>>>>>>>>>>>>> loss: 0.000350012443959713 \n",
      "Epoch 190: >>>>>>>>>>>>>>>>> loss: 0.0002530162746552378  accuracy: 0.7118055555555556\n",
      "Epoch 191: >>>>>>>>>>>>>>>>> loss: 0.000136830989504233 \n",
      "Epoch 192: >>>>>>>>>>>>>>>>> loss: 0.00010955395555356517 \n",
      "Epoch 193: >>>>>>>>>>>>>>>>> loss: 9.182235226035118e-05 \n",
      "Epoch 194: >>>>>>>>>>>>>>>>> loss: 6.543102790601552e-05 \n",
      "Epoch 195: >>>>>>>>>>>>>>>>> loss: 0.00040338444523513317 \n",
      "Epoch 196: >>>>>>>>>>>>>>>>> loss: 0.00013714634405914694 \n",
      "Epoch 197: >>>>>>>>>>>>>>>>> loss: 0.0001505469117546454 \n",
      "Epoch 198: >>>>>>>>>>>>>>>>> loss: 5.5399992561433464e-05 \n",
      "Epoch 199: >>>>>>>>>>>>>>>>> loss: 0.00024895044043660164 \n",
      "Epoch 200: >>>>>>>>>>>>>>>>> loss: 6.585206574527547e-05  accuracy: 0.7083333333333334\n",
      "                0          1          2          3           4          5  \\\n",
      "precision   0.750   0.760870   0.352941   0.200000    0.899083   0.823529   \n",
      "recall      0.375   0.583333   0.315789   0.333333    0.942308   0.913043   \n",
      "f1-score    0.500   0.660377   0.333333   0.250000    0.920188   0.865979   \n",
      "support    16.000  60.000000  38.000000  24.000000  104.000000  46.000000   \n",
      "\n",
      "           accuracy   macro avg  weighted avg  \n",
      "precision  0.697917    0.631070      0.719621  \n",
      "recall     0.697917    0.577135      0.697917  \n",
      "f1-score   0.697917    0.588313      0.700777  \n",
      "support    0.697917  288.000000    288.000000  \n",
      "save checkpoint in : C://Users/Creator/Script/Python/Project/irs_toolbox/models/saved_models/Encoder_64-128-256-512-64-7_mode_clf_on_exp4csipair_finetuning_checkpoint_200__2021_02_10_12_51\n"
     ]
    }
   ],
   "source": [
    "switch('normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
