{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns  # for heatmaps\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = DEVICE\n",
    "torch.cuda.set_device(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.device"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "**Input argument**: tensors \\\n",
    "**Output**: tensors \n",
    "- AlexNet\n",
    "- ResNet  \n",
    "- FrameCNN\n",
    "- ShallowCNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cnn import create_alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [32, 16]           8,208\n",
      "              ReLU-2                   [32, 16]               0\n",
      "           Dropout-3                   [32, 16]               0\n",
      "            Linear-4                    [32, 5]              85\n",
      "              ReLU-5                    [32, 5]               0\n",
      "           Dropout-6                    [32, 5]               0\n",
      "            Linear-7                    [32, 2]              12\n",
      "================================================================\n",
      "Total params: 8,305\n",
      "Trainable params: 8,305\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.11\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def test_model():\n",
    "    pass\n",
    "\n",
    "# test_model()\n",
    "summary(test_model(),input_size=(512,),batch_size=32,device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "**Input argument**: tensors \\\n",
    "**Output**: loss \n",
    "- Cross Entropy Loss (EXAMPLE)\n",
    "- Triplet loss  \n",
    "- NT-Xent\n",
    "- InfoNCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    Train \n",
    "\n",
    "**Input argument**: model, dataloader, loss \\\n",
    "**Output**: model \n",
    "- Supervised learning\n",
    "- Autoencoder Pretraining\n",
    "- Predictive PreTraining \n",
    "- Contrastive Pretraining\n",
    "- Time Contrastive learning\n",
    "- Contrastive Predictive Coding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poutyne import Model,Experiment\n",
    "from losses import NT_Xent\n",
    "from models.utils import Classifier\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torch \n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Supervised_Learning(object):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    encoder_builder (func): callable function of the primary encoder (torch.nn.Module)\n",
    "    batch_size (int): batch size\n",
    "\n",
    "    kwargs:\n",
    "    encoder_builder2 (func): callable function of the secondary encoder (torch.nn.Module)\n",
    "    temperature (float): temperature of NT-Xent\n",
    "    optimizer (func): callable function of optimizer (torch.optim.Optimizer)\n",
    "    supervision (bool): trained with label with Supervised Contrastive Learning (Tian 2020)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,model,**kwargs):\n",
    "        # kwargs\n",
    "        criterion = kwargs.get('criterion',nn.CrossEntropyLoss)\n",
    "        optimizer = kwargs.get('optimizer',torch.optim.Adam)\n",
    "        lr = kwargs.get('lr',0.001)\n",
    "        # overall\n",
    "        self.model = model\n",
    "        self.criterion = criterion(**kwargs)\n",
    "        self.optimizer = optimizer(list(self.model.parameters()), lr=lr)\n",
    "\n",
    "    def train(self,train_loader,epochs=250,verbose=True,rtn_history=True,device=None):\n",
    "        \"\"\"\n",
    "        Return trained model (and history if rtn_history = True)\n",
    "\n",
    "        Args:\n",
    "        train_loader (torch.utils.data.dataloader.DataLoader) - the pair dataset\n",
    "        epochs (int) - epochs\n",
    "        verbose (bool) - verbose\n",
    "        rtn_history (bool) - return both the encoder and history\n",
    "        device (torch.device) - model to be trained on\n",
    "\n",
    "        Return\n",
    "        \"\"\"\n",
    "        history = {'loss':[]}\n",
    "        torch.optim.Optimizer\n",
    "        if device:\n",
    "            self.model = self.model.to(device)\n",
    "            self.criterion = self.criterion.to(device)\n",
    "\n",
    "        for i in range(epochs):\n",
    "            if verbose: print(f'Epoch {i+1} ',end='')\n",
    "            for items in train_loader:\n",
    "\n",
    "                if device:\n",
    "                    X,y = [i.to(device) for i in items]\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                y_pred = self.model(X)\n",
    "\n",
    "                # SupConLoss\n",
    "                if self.supervision:\n",
    "                    loss = self.criterion(y_pred,y)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                X = X.cpu()\n",
    "                y_pred = y_pred.cpu()\n",
    "                y = y.cpu()\n",
    "                del X,y_pred,y\n",
    "                if verbose: print('>',end='')\n",
    "\n",
    "            loss = loss.tolist()\n",
    "            history['loss'].append(loss)\n",
    "            if verbose: print(f' loss: {loss}')\n",
    "\n",
    "        if device:\n",
    "            self.model = self.model.cpu()\n",
    "            self.criterion = self.criterion.cpu()\n",
    "\n",
    "        if rtn_history:\n",
    "            return self.model,history\n",
    "        else:\n",
    "            return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.utils.data.DataLoader(torch.rand(1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "**Input argument**: model, dataframe, train \\\n",
    "**Output**: score/scores \n",
    "- leave-One-Out Validation\n",
    "- Cross Validation  \n",
    "- Cross-Domain Validation\n",
    "- Sample Efficiency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from poutyne import Model,Experiment\n",
    "from data.selection import Selection\n",
    "from data.torchData import DataLoading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cross Validation\n",
    "\n",
    "NUC = 'NUC1'\n",
    "ROOM = 1\n",
    "BATCHSIZE = 64\n",
    "READTYPE = 'npy'\n",
    "NUM_WORKERS = 0\n",
    "OPTIMIZER = 'adam'\n",
    "LOSS = 'cross_entropy'\n",
    "METRICS = ['accuracy','fscore_macro']\n",
    "EPOCHS = 5\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(DEVICE)\n",
    "\n",
    "\n",
    "def data_preparation(dataframe,test_sub,transform,**kwargs):\n",
    "    # parameters\n",
    "    nuc = kwargs.get('nuc',NUC)\n",
    "    room = kwargs.get('room',ROOM)\n",
    "    batch_size = kwargs.get('batch_size',BATCHSIZE)\n",
    "    readtype = kwargs.get('readtype',READTYPE)\n",
    "    num_workers = kwargs.get('num_workers',NUM_WORKERS)\n",
    "    # selection\n",
    "    selection = Selection(split='loov',test_sub=test_sub,nuc=nuc,room=room)\n",
    "    df_train,_,df_test = dataselection(dataframe)\n",
    "    # loading\n",
    "    data_loading = DataLoading(transform=transform,batch_size=batch_size,readtype=readtype,\n",
    "                               num_workers=num_workers,shuffle=False)\n",
    "    test_loading = DataLoading(transform=transform,batch_size=len(df_test),readtype=readtype,\n",
    "                               num_workers=num_workers,shuffle=False)\n",
    "    train_loader = data_loading(df_train)\n",
    "    test_loader  = test_loading(df_test)\n",
    "    return train_loader,test_loader\n",
    "\n",
    "def append_record(history,record,metrics):\n",
    "    df = pd.DataFrame(history)\n",
    "    row = df.loc[len(df)-1,metrics]\n",
    "    record.append(row)\n",
    "    return record\n",
    "\n",
    "def leaveOneOut_crossValidation(model,dataframe,transform,verbose=True,**kwargs):\n",
    "    \n",
    "    device = kwargs.get('device',DEVICE)\n",
    "    optimizer = kwargs.get('optimizer',OPTIMIZER)\n",
    "    loss = kwargs.get('loss',LOSS)\n",
    "    metrics = kwargs.get('metrics',METRICS)\n",
    "    epochs = kwargs.get('epochs',EPOCHS)\n",
    "    \n",
    "    records = []\n",
    "    \n",
    "    for test_sub in dataframe['person'].unique():\n",
    "        \n",
    "        if verbose: print(test_sub)\n",
    "        \n",
    "        model.build()\n",
    "        \n",
    "        train_loader,test_loader = data_preparation(dataframe,test_sub,transform)\n",
    "        \n",
    "        mdl = Model(model,OPTIMIZER,LOSS,batch_metrics=METRICS).to(device)\n",
    "        history = mdl.fit(train_loader, test_loader, epochs=EPOCHS)\n",
    "        records = append_record(history,records,METRICS)\n",
    "    \n",
    "    average_scores = pd.DataFrame(records).mean()\n",
    "    return average_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from time import gmtime, strftime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor, nn\n",
    "import poutyne\n",
    "from poutyne import Model,Experiment\n",
    "\n",
    "from data.custom_data import filepath_dataframe\n",
    "from data.selection import Selection\n",
    "from data.transformation import Transform_CnnLstmS,Transform_CnnS\n",
    "from data.torchData import DataLoadings,DataLoading\n",
    "\n",
    "from data.custom_data import nucPaired_fpDataframe\n",
    "from data.torchData import PairDataLoading,DataLoading\n",
    "from training.contrastive_pretraining import Contrastive_PreTraining\n",
    "from training.finetuning import FineTuneCNN\n",
    "from validation.loov import leaveOneOut_crossValidation\n",
    "\n",
    "import models\n",
    "\n",
    "#####################################################################################################################\n",
    "\n",
    "# random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# gpu setting\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(DEVICE)\n",
    "device = DEVICE\n",
    "\n",
    "## I/O directory\n",
    "data_dir  = 'E:\\\\external_data\\\\opera_csi\\\\Session_2\\\\experiment_data\\\\experiment_data\\\\exp_7_amp_spec_only\\\\npy_format'\n",
    "readtype = 'npy'\n",
    "splitchar = '\\\\'\n",
    "record_outpath = './record'\n",
    "\n",
    "# data selection\n",
    "dataselection_name = 'EXP7-NUC1-Room1-Amp-RandomSplit-ResReduced'\n",
    "\n",
    "data_selection = Selection(split='random',test_sub=0.2,val_sub=0.1,\n",
    "                           nuc='NUC1',room=1,sample_per_class=None)\n",
    "\n",
    "# data loading\n",
    "transform = Transform_CnnS()\n",
    "batch_size = 64\n",
    "num_workers = 0\n",
    "\n",
    "# training\n",
    "optimizer_builder = torch.optim.SGD\n",
    "lr = 0.001\n",
    "epochs = 1\n",
    "\n",
    "network_name = 'AlexNet'\n",
    "\n",
    "# Experiment Name\n",
    "comment = 'TestModel'\n",
    "exp_name = f'{network_name}_Supervised_{dataselection_name}_Comment-{comment}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda Availability:  True\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------Main-------------------------------------------\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "# print('Experiment Name: ',exp_name)\n",
    "print('Cuda Availability: ',torch.cuda.is_available())\n",
    "# data preparation\n",
    "df = filepath_dataframe(data_dir,splitchar)\n",
    "df = nucPaired_fpDataframe(df)\n",
    "df_train,df_val,df_test = data_selection(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 >>>>>>>>>>>>>>>>>>>> loss: 6.898321151733398\n"
     ]
    }
   ],
   "source": [
    "##### PRE-TRAIN ######\n",
    "\n",
    "# data loading\n",
    "pretrain_loading = PairDataLoading(transform=transform,batch_size=batch_size,readtype=readtype,\n",
    "                                        num_workers=num_workers,drop_last=True,supervision=True)\n",
    "pretrain_loader = pretrain_loading(df_train)\n",
    "\n",
    "# train objective \n",
    "train_objective = Contrastive_PreTraining(models.cnn.create_alexnet,batch_size=batch_size,\n",
    "                                          supervision=None,temperature=0.1/0.07)\n",
    "encoder,history = train_objective.train(pretrain_loader,epochs=epochs,device=device)\n",
    "# save model \n",
    "model_path = f'./models/saved_models/Encoder___{exp_name}'\n",
    "torch.save(encoder.state_dict(),model_path)\n",
    "del encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FINE-TUNING #####\n",
    "\n",
    "# data loading\n",
    "data_loading = DataLoading(transform=transform,batch_size=batch_size,readtype=readtype,\n",
    "                           num_workers=num_workers,drop_last=True)\n",
    "test_loading = DataLoading(transform=transform,batch_size=len(df_test),readtype=readtype,\n",
    "                           num_workers=num_workers,drop_last=True)\n",
    "\n",
    "df_train = df_train.rename(columns = {'fullpath_x':'fullpath'})\n",
    "df_val   = df_val.rename(columns = {'fullpath_x':'fullpath'})\n",
    "df_test  = df_test.rename(columns = {'fullpath_x':'fullpath'})\n",
    "\n",
    "train_loader = data_loading(df_train)\n",
    "val_loader   = data_loading(df_val)\n",
    "test_loader  = test_loading(df_test)\n",
    "\n",
    "# load and create model\n",
    "model = FineTuneCNN(model_path=model_path,\n",
    "                    encoder_builder=models.cnn.create_alexnet,\n",
    "                    n_classes=df.activity.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with poutyne\n",
    "mdl = Model(model,'adam','cross_entropy',batch_metrics=['accuracy']).to(device)\n",
    "history = mdl.fit_generator(train_generator=train_loader,valid_generator=test_loader,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "\u001b[35mEpoch: \u001b[36m1/1 \u001b[35mStep: \u001b[36m26/26 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m53.40s \u001b[35mloss:\u001b[94m 664.328237\u001b[35m acc:\u001b[94m 25.155666\u001b[35m fscore_micro:\u001b[94m 0.251557\u001b[35m fscore_macro:\u001b[94m 0.089718\u001b[35m val_loss:\u001b[94m 1.789191\u001b[35m val_acc:\u001b[94m 27.272728\u001b[35m val_fscore_micro:\u001b[94m 0.272727\u001b[35m val_fscore_macro:\u001b[94m 0.136806\u001b[0m\n",
      "Two\n",
      "\u001b[35mEpoch: \u001b[36m1/1 \u001b[35mStep: \u001b[36m25/25 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m59.72s \u001b[35mloss:\u001b[94m 318.538498\u001b[35m acc:\u001b[94m 25.031766\u001b[35m fscore_micro:\u001b[94m 0.250318\u001b[35m fscore_macro:\u001b[94m 0.101809\u001b[35m val_loss:\u001b[94m 1.793202\u001b[35m val_acc:\u001b[94m 16.666668\u001b[35m val_fscore_micro:\u001b[94m 0.166667\u001b[35m val_fscore_macro:\u001b[94m 0.047619\u001b[0m\n",
      "Three\n",
      "\u001b[35mEpoch: \u001b[36m1/1 \u001b[35mStep: \u001b[36m22/22 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m54.87s \u001b[35mloss:\u001b[94m 1087.395635\u001b[35m acc:\u001b[94m 48.887294\u001b[35m fscore_micro:\u001b[94m 0.488873\u001b[35m fscore_macro:\u001b[94m 0.232042\u001b[35m val_loss:\u001b[94m 1.793351\u001b[35m val_acc:\u001b[94m 16.666668\u001b[35m val_fscore_micro:\u001b[94m 0.166667\u001b[35m val_fscore_macro:\u001b[94m 0.047619\u001b[0m\n",
      "Four\n",
      "\u001b[35mEpoch: \u001b[36m1/1 \u001b[35mStep: \u001b[36m27/27 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m60.28s \u001b[35mloss:\u001b[94m 963.206195\u001b[35m acc:\u001b[94m 30.930233\u001b[35m fscore_micro:\u001b[94m 0.309302\u001b[35m fscore_macro:\u001b[94m 0.132405\u001b[35m val_loss:\u001b[94m 1.792317\u001b[35m val_acc:\u001b[94m 16.666668\u001b[35m val_fscore_micro:\u001b[94m 0.166667\u001b[35m val_fscore_macro:\u001b[94m 0.047619\u001b[0m\n",
      "Five\n",
      "\u001b[35mEpoch: \u001b[36m1/1 \u001b[35mStep: \u001b[36m25/25 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m61.32s \u001b[35mloss:\u001b[94m 586.714330\u001b[35m acc:\u001b[94m 31.913541\u001b[35m fscore_micro:\u001b[94m 0.319135\u001b[35m fscore_macro:\u001b[94m 0.142668\u001b[35m val_loss:\u001b[94m 1.792724\u001b[35m val_acc:\u001b[94m 16.666668\u001b[35m val_fscore_micro:\u001b[94m 0.166667\u001b[35m val_fscore_macro:\u001b[94m 0.047619\u001b[0m\n",
      "Six\n",
      "\u001b[35mEpoch: \u001b[36m1/1 \u001b[35mStep: \u001b[36m25/25 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m54.98s \u001b[35mloss:\u001b[94m 501.515574\u001b[35m acc:\u001b[94m 48.968105\u001b[35m fscore_micro:\u001b[94m 0.489681\u001b[35m fscore_macro:\u001b[94m 0.247380\u001b[35m val_loss:\u001b[94m 1.792662\u001b[35m val_acc:\u001b[94m 16.666668\u001b[35m val_fscore_micro:\u001b[94m 0.166667\u001b[35m val_fscore_macro:\u001b[94m 0.047619\u001b[0m\n",
      "Seven\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = df.rename(columns = {'fullpath_x':'fullpath'})\n",
    "df_1 = df[df['room']==1]\n",
    "average_scores = leaveOneOut_crossValidation(model,df,transform,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, vgg16, alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = alexnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.classifier = Classifier(9216,16,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 64, 16, 399]          23,296\n",
      "              ReLU-2          [-1, 64, 16, 399]               0\n",
      "         MaxPool2d-3           [-1, 64, 7, 199]               0\n",
      "            Conv2d-4          [-1, 192, 7, 199]         307,392\n",
      "              ReLU-5          [-1, 192, 7, 199]               0\n",
      "         MaxPool2d-6           [-1, 192, 3, 99]               0\n",
      "            Conv2d-7           [-1, 384, 3, 99]         663,936\n",
      "              ReLU-8           [-1, 384, 3, 99]               0\n",
      "            Conv2d-9           [-1, 256, 3, 99]         884,992\n",
      "             ReLU-10           [-1, 256, 3, 99]               0\n",
      "           Conv2d-11           [-1, 256, 3, 99]         590,080\n",
      "             ReLU-12           [-1, 256, 3, 99]               0\n",
      "        MaxPool2d-13           [-1, 256, 1, 49]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
      "           Linear-15                   [-1, 16]         147,472\n",
      "        LeakyReLU-16                   [-1, 16]               0\n",
      "          Dropout-17                   [-1, 16]               0\n",
      "           Linear-18                    [-1, 6]             102\n",
      "       Classifier-19                    [-1, 6]               0\n",
      "================================================================\n",
      "Total params: 2,617,270\n",
      "Trainable params: 2,617,270\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.28\n",
      "Forward/backward pass size (MB): 15.66\n",
      "Params size (MB): 9.98\n",
      "Estimated Total Size (MB): 26.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(k,(3,70,1600),device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
