{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn  # for heatmaps\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.io import loadmat\n",
    "\n",
    "# link = r\"D:\\external_data\\Experiment4\"\n",
    "# filename = r\"\\Dataset_PWR_WiFi.mat\"\n",
    "# directory = link + filename\n",
    "\n",
    "# mat = loadmat(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import experimental dataset 2\n",
    "# folderpath2 = \"D:/external_data/Experiment3/csv_files/exp_2\"  # CHANGE THIS IF THE PATH CHANGED\n",
    "# df_exp2 = import_clean_data('exp2',folderpath2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data.import_data import import_experimental_data\n",
    "\n",
    "# 1. Import data\n",
    "folderpath1 = \"E:/external_data/Experiment3/csv_files/exp_1\"\n",
    "df = import_clean_data('exp1',folderpath1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.train import seperate_dataframes\n",
    "from data.process_data import DatasetObject, slide_augmentation\n",
    "from data import process_data\n",
    "\n",
    "\n",
    "X, y = seperate_dataframes(df_exp1)\n",
    "\n",
    "datasetobj = DatasetObject()\n",
    "datasetobj.import_data(X, y)\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "window_size = 900\n",
    "slide_size = 200\n",
    "datasetobj.data_transform(lambda x,y,z : process_data.slide_augmentation(x, y, z,\n",
    "                                                            window_size=window_size,\n",
    "                                                            slide_size=slide_size,\n",
    "                                                            skip_labels=['noactivity']),axis=0)\n",
    "# datasetobj.data_transform(lambda arr: arr.reshape(-1,window_size,3,30).transpose(0,2,1,3),axis=1, col=0)\n",
    "datasetobj.data_transform(lambda arr: arr.reshape(-1,window_size,3,30).transpose(0,2,3,1),axis=1, col=0)\n",
    "datasetobj.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = datasetobj.data[0,0],datasetobj.data[0,1]\n",
    "\n",
    "\n",
    "num = 102\n",
    "channel = 0\n",
    "X,y = X[num][channel],y[num]\n",
    "\n",
    "# channel = 0\n",
    "# X = X[channel]\n",
    "# X = X.reshape(900,30,3)\n",
    "# X = X.transpose(2,0,1)[0]\n",
    "\n",
    "for i in [1,3,5,10,30,60]:\n",
    "    X_ = X[::3,::i]\n",
    "\n",
    "    print(X_.shape)\n",
    "    plt.figure(figsize=(15,20))\n",
    "    plt.imshow(X_,cmap='jet')\n",
    "    plt.title(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X[:,60:90]\n",
    "print(a.shape)\n",
    "a.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.process_data import breakpoints\n",
    "\n",
    "def breakpoints(ls):\n",
    "    dic = {}\n",
    "    for i in range(len(ls)-1):\n",
    "        if ls[i+1] != ls[i]:\n",
    "            string = f\"{ls[i]}-{ls[i+1]}\"\n",
    "            dic[string] = i\n",
    "    return dic\n",
    "\n",
    "points = breakpoints(y_ls[0].reshape(-1).tolist())\n",
    "print(points)\n",
    "print('cutpoint: ',y_ls[0].shape[0]//8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1 = X_ls[0].transpose()\n",
    "user1_c = user1.reshape(3,30,-1)\n",
    "user1_bendfwd_ = user1[:,:6999]\n",
    "user1_kneel_   = user1[:,6999:6999+6999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,50))\n",
    "p = 3000\n",
    "plt.imshow(user1_c[1][:,p:p+2000],cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,50))\n",
    "p = 3000\n",
    "sample = user1[:,p:p+2000]\n",
    "# MinMaxScaler().fit_transform(sample)\n",
    "plt.imshow(sample,cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ls[0][p:p+6999,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1_X = X_ls[0]\n",
    "user1_y = y_ls[0]\n",
    "\n",
    "# Section\n",
    "# p = 6999*1\n",
    "\n",
    "for p in range(0,6999*8,6999):\n",
    "\n",
    "    sample = user1[p:p+6999,:]\n",
    "\n",
    "\n",
    "\n",
    "    # Scale along first axis \n",
    "    # sample = MinMaxScaler().fit_transform(sample)\n",
    "\n",
    "    # Transpose \n",
    "    sample = sample.transpose()\n",
    "\n",
    "    # ImShow\n",
    "    plt.figure(figsize = (25,150))\n",
    "    plt.imshow(sample,cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6999*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ls[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise spectrogram\n",
    "img = img.transpose()\n",
    "img = img[:,::10]\n",
    "plt.figure(figsize = (15,50))\n",
    "plt.imshow(img,cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from data.process_data import stacking\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def visual_spectrogram(img,title='spectrogram'):\n",
    "    \n",
    "    if len(img.shape) == 3:\n",
    "        \n",
    "        img.squeeze()\n",
    "    \n",
    "    img = MinMaxScaler(feature_range=(0,1)).fit_transform(img)\n",
    "    \n",
    "#     img = img.reshape(*img.shape[:-1],1)\n",
    "    \n",
    "#     img = np.concatenate((img,img,img),axis=2)\n",
    "    \n",
    "    plt.figure(figsize = (15,50))\n",
    "    plt.imshow(img,cmap='jet')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "        \n",
    "#visualize weights for alexnet - first conv layer\n",
    "alexnet = models.alexnet(pretrained=False)\n",
    "\n",
    "# Store all conv layer in alexnet\n",
    "k = []\n",
    "for m in alexnet.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(m.weight.data.shape)\n",
    "        k.append(m)\n",
    "    else:  \n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_single_filter(weight):\n",
    "    \n",
    "    img = MinMaxScaler(feature_range=(0,1)).fit_transform(weight)\n",
    "    \n",
    "#     img = img.reshape(*img.shape[:-1],1)\n",
    "    \n",
    "#     img = np.concatenate((img,img,img),axis=2)\n",
    "    \n",
    "#     plt.figure(figsize = (15,10))\n",
    "    plt.imshow(weight,cmap='jet')\n",
    "#     plt.show()\n",
    "    \n",
    "    return \n",
    "\n",
    "def visualise_filters(layer,figsize=(20,15)):\n",
    "    \n",
    "    weights = layer.weight.data\n",
    "\n",
    "    if weights.shape[0] > weights.shape[1]:\n",
    "        \n",
    "        weights = weights.transpose(1,0)\n",
    "        \n",
    "    rows = weights.shape[0]\n",
    "    \n",
    "    cols = weights.shape[1]\n",
    "    \n",
    "    axes = []\n",
    "    \n",
    "    fig= plt.figure()\n",
    "\n",
    "    for n in range(rows):\n",
    "\n",
    "        for c in range(cols):\n",
    "            \n",
    "            axes.append(fig.add_subplot(rows, cols, n*cols+c+1))\n",
    "\n",
    "            single_filter = weights[n,c]\n",
    "        \n",
    "            visual_single_filter(single_filter)\n",
    "            \n",
    "#     fig.tight_layout()    \n",
    "    \n",
    "    plt.show()     \n",
    "    \n",
    "    return \n",
    "\n",
    "visualise_filters(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import gmtime, strftime\n",
    "# a = time.time()\n",
    "# model  = train(model, train_loader, criterion, optimizer, 48)\n",
    "# print(time.time() - a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchsummary import summary\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.baseline import Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### extra setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "\n",
    "torch.cuda.device_count()\n",
    "\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x247630b13b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1024)\n",
    "torch.manual_seed(1024)\n",
    "# torch.set_deterministic(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "# torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self,X):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_Block(nn.Module):\n",
    "    \"\"\"\n",
    "    Single channel for radio image (30,30,1)\n",
    "    \"\"\"\n",
    "    def __init__(self,in_feature,out_feature,kernel_size,stride, padding='zeros', bias=False):\n",
    "        super(Residual_Block, self).__init__()\n",
    "        ### 1st ###\n",
    "        self.conv1 = nn.Conv2d(in_feature,out_feature,kernel_size=kernel_size,stride=stride, bias=bias)\n",
    "        self.norm1 = nn.BatchNorm2d(out_feature)\n",
    "        self.actv1 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=kernel_size,stride=stride)\n",
    "        self.covr1 = nn.Conv2d(in_feature,out_feature,kernel_size=1,stride=1, bias=False)\n",
    "        ### 2nd ###\n",
    "        self.conv2 = nn.Conv2d(out_feature,out_feature,kernel_size=kernel_size,stride=stride, bias=bias)\n",
    "        self.norm2 = nn.BatchNorm2d(out_feature)\n",
    "        self.actv2 = nn.ReLU(inplace=True)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=kernel_size,stride=stride)\n",
    "        \n",
    "        self.covr1.weight.requires_grad = False\n",
    "        \n",
    "    def forward(self,X):\n",
    "        R = X\n",
    "        ### 1st ###\n",
    "        X = self.actv1(self.norm1(self.conv1(X)))\n",
    "        R = self.covr1(self.pool1(R))\n",
    "        ### 2nd ###\n",
    "        X = self.norm2(self.conv2(X))\n",
    "        R = self.pool2(R)\n",
    "        # print(X.shape,R.shape)\n",
    "        X += R\n",
    "        X = self.actv2(X)\n",
    "        return X\n",
    "\n",
    "    \n",
    "class Residual(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Residual, self).__init__()\n",
    "        self.norm = nn.BatchNorm2d(1)\n",
    "        self.block1 = Residual_Block(in_feature=  1, out_feature=  64, kernel_size = (5,5), stride = (1,2))\n",
    "        self.block2 = Residual_Block(in_feature= 64, out_feature= 128, kernel_size = (4,4), stride = (2,2))\n",
    "        self.block3 = Residual_Block(in_feature=128, out_feature= 256, kernel_size = (3,3), stride = (2,2))\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,3))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.norm(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = torch.flatten(self.pool(x), 1)\n",
    "        return x\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_View(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    This model first divides a spectrogram into number of pieces based on window and channel,\n",
    "    each piece is processed with the single encoder and output a matrix with shape (batch_size, seq_size, num_features),\n",
    "    input shape: (batch_size,num_frame,num_channel)\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder=None):\n",
    "        super(Encoder_View, self).__init__()\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def forward(self,x):\n",
    "        ### Method 1 ###\n",
    "#         size = x.shape\n",
    "#         x = x.view(-1,1,30,900)\n",
    "#         x = self.encoder(x)\n",
    "#         x = x.view(size[0],-1)\n",
    "        ### Method 2 ###\n",
    "        a,b,c = torch.split(x,1,dim=1)\n",
    "        a = self.encoder(a)\n",
    "        b = self.encoder(b)\n",
    "        c = self.encoder(c)\n",
    "        x = (a+b+c)/3\n",
    "        return x\n",
    "\n",
    "# a = time.time()\n",
    "# sample = torch.rand(size=(64,3,30,900))\n",
    "# full_encoder = Encoder_View(encoder=Encoder())\n",
    "# sample = full_encoder(sample)\n",
    "# sample.shape\n",
    "# print(time.time()-a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Shallow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 32, 28, 898]             320\n",
      "       BatchNorm2d-2          [-1, 32, 28, 898]              64\n",
      "              ReLU-3          [-1, 32, 28, 898]               0\n",
      " AdaptiveMaxPool2d-4          [-1, 32, 20, 300]               0\n",
      "            Conv2d-5          [-1, 64, 18, 298]          18,496\n",
      "       BatchNorm2d-6          [-1, 64, 18, 298]             128\n",
      "              ReLU-7          [-1, 64, 18, 298]               0\n",
      " AdaptiveMaxPool2d-8          [-1, 64, 10, 100]               0\n",
      "            Conv2d-9           [-1, 128, 8, 98]          73,856\n",
      "      BatchNorm2d-10           [-1, 128, 8, 98]             256\n",
      "             ReLU-11           [-1, 128, 8, 98]               0\n",
      "AdaptiveMaxPool2d-12           [-1, 128, 5, 30]               0\n",
      "           Conv2d-13           [-1, 256, 3, 28]         295,168\n",
      "           Lambda-14           [-1, 256, 3, 28]               0\n",
      "             Tanh-15           [-1, 256, 3, 28]               0\n",
      "AdaptiveAvgPool2d-16            [-1, 256, 2, 4]               0\n",
      "================================================================\n",
      "Total params: 388,288\n",
      "Trainable params: 388,288\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.10\n",
      "Forward/backward pass size (MB): 31.18\n",
      "Params size (MB): 1.48\n",
      "Estimated Total Size (MB): 32.76\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    4 layers\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        ### 1st ###\n",
    "        self.conv1 = nn.Conv2d(1,32,kernel_size=(3,3),stride=(1,1),padding=0)\n",
    "        self.actv1 = nn.ReLU()\n",
    "        self.norm1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.AdaptiveMaxPool2d((20,300))\n",
    "        ### 2nd ###\n",
    "        self.conv2 = nn.Conv2d(32,64,kernel_size=(3,3),stride=(1,1),padding=0)\n",
    "        self.actv2 = nn.ReLU()\n",
    "        self.norm2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.AdaptiveMaxPool2d((10,100))\n",
    "        ### 3rd ###\n",
    "        self.conv3 = nn.Conv2d(64,128,kernel_size=(3,3),stride=(1,1),padding=0)\n",
    "        self.actv3 = nn.ReLU()\n",
    "        self.norm3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.AdaptiveMaxPool2d((5,30))\n",
    "        ### 4rd ###\n",
    "        self.conv4 = nn.Conv2d(128,256,kernel_size=(3,3),stride=(1,1),padding=0)\n",
    "        self.actv4 = nn.Tanh()\n",
    "        self.norm4 = Lambda(lambda x:x)\n",
    "        self.pool4 = nn.AdaptiveAvgPool2d((2,4))\n",
    "        \n",
    "    def forward(self,X):\n",
    "        X = self.pool1(self.actv1(self.norm1(self.conv1(X))))\n",
    "        X = self.pool2(self.actv2(self.norm2(self.conv2(X))))\n",
    "        X = self.pool3(self.actv3(self.norm3(self.conv3(X))))\n",
    "        X = self.pool4(self.actv4(self.norm4(self.conv4(X))))\n",
    "        X = torch.flatten(X, 1)\n",
    "        return X\n",
    "    \n",
    "summary(Encoder().cuda(),input_size=(1,30,900))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.SimCLR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projection_Head(nn.Module):\n",
    "    \n",
    "    def __init__(self,feature_in,feature_out):\n",
    "        super(Projection_Head, self).__init__()\n",
    "        # self.layer1 = nn.Linear(feature_in,feature_in)\n",
    "        self.layer2 = nn.Linear(feature_in,feature_out)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        # X = self.layer1(X)\n",
    "        X = self.layer2(X)\n",
    "        return X\n",
    "\n",
    "class SimCLR_TXR_model(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(SimCLR_TXR_model, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self,x):\n",
    "        a,b,c = torch.split(x,1,dim=1)\n",
    "        a = self.encoder(a)\n",
    "        b = self.encoder(b)\n",
    "        c = self.encoder(c)\n",
    "        a = self.decoder(a)\n",
    "        b = self.decoder(b)\n",
    "        c = self.decoder(c)\n",
    "        return a,b,c\n",
    "\n",
    "# encoder = Encoder()\n",
    "# decoder = Projection_Head(768,128)\n",
    "# model = SimCLR_TXR_model(encoder=encoder,decoder=decoder)\n",
    "# summary(model=model.cuda(),input_size=(3,30,900),batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Contrastive_multiview_loss(nn.Module):\n",
    "    \n",
    "    def __init__(self,loss_func):\n",
    "        super(Contrastive_multiview_loss, self).__init__()\n",
    "        self.loss_func = loss_func \n",
    "        \n",
    "    def forward(self,*vecs):\n",
    "        loss = sum([self.loss_func(vecs[i],vecs[j]) for i in range(0,len(vecs)-1) for j in range(i+1,len(vecs))])\n",
    "#         loss = torch.tensor(0)\n",
    "#         for i in range(0,len(vecs)-1):\n",
    "#             for j in range(i+1,len(vecs)):\n",
    "#                 cur = self.loss_func(vecs[i],vecs[j])\n",
    "#                 loss = loss.add(cur)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "# encoder = Encoder()\n",
    "# decoder = Projection_Head(768,128)\n",
    "# model = SimCLR_TXR_model(encoder=encoder,decoder=decoder)\n",
    "# loss_func = NT_Xent(64,1)\n",
    "# multiview_loss = Contrastive_multiview_loss(loss_func)\n",
    "\n",
    "\n",
    "# sample = torch.rand((64,3,30,900))\n",
    "# a,b,c = model(sample)\n",
    "# loss = multiview_loss(a,b,c)\n",
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. calling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pretraining\n",
    "# def create_model():\n",
    "#     encoder = Encoder()\n",
    "#     decoder = Projection_Head(2048,128)\n",
    "#     model = SimCLR_TXR_model(encoder=encoder,decoder=decoder)\n",
    "#     return model\n",
    "\n",
    "# def setting(model):\n",
    "#     \"\"\"\n",
    "#     NTXent\n",
    "#     \"\"\"\n",
    "# #     criterion = NT_Xent(batch_size=64,temperature=0.1)\n",
    "#     criterion = Contrastive_multiview_loss(loss_func=NT_Xent(128,1))\n",
    "#     optimizer = torch.optim.Adam(list(model.parameters()), lr=0.0005)\n",
    "#     return criterion, optimizer\n",
    "\n",
    "\n",
    "# model = create_model()\n",
    "# model = create_model().to(device)\n",
    "# summary(create_model().cuda(),(3,30,900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.baseline import Classifier,CNN_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 32, 28, 898]             320\n",
      "       BatchNorm2d-2          [-1, 32, 28, 898]              64\n",
      "              ReLU-3          [-1, 32, 28, 898]               0\n",
      " AdaptiveMaxPool2d-4          [-1, 32, 20, 300]               0\n",
      "            Conv2d-5          [-1, 64, 18, 298]          18,496\n",
      "       BatchNorm2d-6          [-1, 64, 18, 298]             128\n",
      "              ReLU-7          [-1, 64, 18, 298]               0\n",
      " AdaptiveMaxPool2d-8          [-1, 64, 10, 100]               0\n",
      "            Conv2d-9           [-1, 128, 8, 98]          73,856\n",
      "      BatchNorm2d-10           [-1, 128, 8, 98]             256\n",
      "             ReLU-11           [-1, 128, 8, 98]               0\n",
      "AdaptiveMaxPool2d-12           [-1, 128, 5, 30]               0\n",
      "           Conv2d-13           [-1, 256, 3, 28]         295,168\n",
      "           Lambda-14           [-1, 256, 3, 28]               0\n",
      "             Tanh-15           [-1, 256, 3, 28]               0\n",
      "AdaptiveAvgPool2d-16            [-1, 256, 2, 4]               0\n",
      "          Encoder-17                 [-1, 2048]               0\n",
      "           Conv2d-18          [-1, 32, 28, 898]             320\n",
      "      BatchNorm2d-19          [-1, 32, 28, 898]              64\n",
      "             ReLU-20          [-1, 32, 28, 898]               0\n",
      "AdaptiveMaxPool2d-21          [-1, 32, 20, 300]               0\n",
      "           Conv2d-22          [-1, 64, 18, 298]          18,496\n",
      "      BatchNorm2d-23          [-1, 64, 18, 298]             128\n",
      "             ReLU-24          [-1, 64, 18, 298]               0\n",
      "AdaptiveMaxPool2d-25          [-1, 64, 10, 100]               0\n",
      "           Conv2d-26           [-1, 128, 8, 98]          73,856\n",
      "      BatchNorm2d-27           [-1, 128, 8, 98]             256\n",
      "             ReLU-28           [-1, 128, 8, 98]               0\n",
      "AdaptiveMaxPool2d-29           [-1, 128, 5, 30]               0\n",
      "           Conv2d-30           [-1, 256, 3, 28]         295,168\n",
      "           Lambda-31           [-1, 256, 3, 28]               0\n",
      "             Tanh-32           [-1, 256, 3, 28]               0\n",
      "AdaptiveAvgPool2d-33            [-1, 256, 2, 4]               0\n",
      "          Encoder-34                 [-1, 2048]               0\n",
      "           Conv2d-35          [-1, 32, 28, 898]             320\n",
      "      BatchNorm2d-36          [-1, 32, 28, 898]              64\n",
      "             ReLU-37          [-1, 32, 28, 898]               0\n",
      "AdaptiveMaxPool2d-38          [-1, 32, 20, 300]               0\n",
      "           Conv2d-39          [-1, 64, 18, 298]          18,496\n",
      "      BatchNorm2d-40          [-1, 64, 18, 298]             128\n",
      "             ReLU-41          [-1, 64, 18, 298]               0\n",
      "AdaptiveMaxPool2d-42          [-1, 64, 10, 100]               0\n",
      "           Conv2d-43           [-1, 128, 8, 98]          73,856\n",
      "      BatchNorm2d-44           [-1, 128, 8, 98]             256\n",
      "             ReLU-45           [-1, 128, 8, 98]               0\n",
      "AdaptiveMaxPool2d-46           [-1, 128, 5, 30]               0\n",
      "           Conv2d-47           [-1, 256, 3, 28]         295,168\n",
      "           Lambda-48           [-1, 256, 3, 28]               0\n",
      "             Tanh-49           [-1, 256, 3, 28]               0\n",
      "AdaptiveAvgPool2d-50            [-1, 256, 2, 4]               0\n",
      "          Encoder-51                 [-1, 2048]               0\n",
      "     Encoder_View-52                 [-1, 2048]               0\n",
      "           Linear-53                  [-1, 128]         262,272\n",
      "           Linear-54                    [-1, 8]           1,032\n",
      "       Classifier-55                    [-1, 8]               0\n",
      "================================================================\n",
      "Total params: 1,428,168\n",
      "Trainable params: 1,428,168\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.31\n",
      "Forward/backward pass size (MB): 93.60\n",
      "Params size (MB): 5.45\n",
      "Estimated Total Size (MB): 99.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    \"\"\"\n",
    "    V3\n",
    "    \"\"\"\n",
    "    encoder = Encoder_View(encoder=Encoder())\n",
    "    decoder = Classifier(2048)\n",
    "    model = CNN_module(encoder=encoder,decoder=decoder)\n",
    "    return model\n",
    "\n",
    "summary(create_model(),input_size=(3,30,900),device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import process_data\n",
    "from data.import_data import import_clean_data\n",
    "from data.datasetobj import DatasetObject\n",
    "# from models.train import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from models.train import prepare_data\n",
    "\n",
    "# train_loader, test_loader = prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 files.\n",
      "input_user10_bendfwd.csv annotation_user10_bendfwd.csv user10\n",
      "input_user10_kneel.csv annotation_user10_kneel.csv user10\n",
      "input_user10_lie.csv annotation_user10_lie.csv user10\n",
      "input_user10_sit.csv annotation_user10_sit.csv user10\n",
      "input_user10_sitrotate.csv annotation_user10_sitrotate.csv user10\n",
      "input_user10_stand.csv annotation_user10_stand.csv user10\n",
      "input_user10_standrotate.csv annotation_user10_standrotate.csv user10\n",
      "input_user10_walking.csv annotation_user10_walking.csv user10\n",
      "input_user1_bendfwd.csv annotation_user1_bendfwd.csv user1\n",
      "input_user1_kneel.csv annotation_user1_kneel.csv user1\n",
      "input_user1_lie.csv annotation_user1_lie.csv user1\n",
      "input_user1_sit.csv annotation_user1_sit.csv user1\n",
      "input_user1_sitrotate.csv annotation_user1_sitrotate.csv user1\n",
      "input_user1_stand.csv annotation_user1_stand.csv user1\n",
      "input_user1_standrotate.csv annotation_user1_standrotate.csv user1\n",
      "input_user1_walking.csv annotation_user1_walking.csv user1\n",
      "input_user2_bendfwd.csv annotation_user2_bendfwd.csv user2\n",
      "input_user2_kneel.csv annotation_user2_kneel.csv user2\n",
      "input_user2_lie.csv annotation_user2_lie.csv user2\n",
      "input_user2_sit.csv annotation_user2_sit.csv user2\n",
      "input_user2_sitrotate.csv annotation_user2_sitrotate.csv user2\n",
      "input_user2_stand.csv annotation_user2_stand.csv user2\n",
      "input_user2_standrotate.csv annotation_user2_standrotate.csv user2\n",
      "input_user2_walking.csv annotation_user2_walking.csv user2\n",
      "input_user3_bendfwd.csv annotation_user3_bendfwd.csv user3\n",
      "input_user3_kneel.csv annotation_user3_kneel.csv user3\n",
      "input_user3_lie.csv annotation_user3_lie.csv user3\n",
      "input_user3_sit.csv annotation_user3_sit.csv user3\n",
      "input_user3_sitrotate.csv annotation_user3_sitrotate.csv user3\n",
      "input_user3_stand.csv annotation_user3_stand.csv user3\n",
      "input_user3_standrotate.csv annotation_user3_standrotate.csv user3\n",
      "input_user3_walking.csv annotation_user3_walking.csv user3\n",
      "input_user4_bendfwd.csv annotation_user4_bendfwd.csv user4\n",
      "input_user4_kneel.csv annotation_user4_kneel.csv user4\n",
      "input_user4_lie.csv annotation_user4_lie.csv user4\n",
      "input_user4_sit.csv annotation_user4_sit.csv user4\n",
      "input_user4_sitrotate.csv annotation_user4_sitrotate.csv user4\n",
      "input_user4_stand.csv annotation_user4_stand.csv user4\n",
      "input_user4_standrotate.csv annotation_user4_standrotate.csv user4\n",
      "input_user4_walking.csv annotation_user4_walking.csv user4\n",
      "input_user5_bendfwd.csv annotation_user5_bendfwd.csv user5\n",
      "input_user5_kneel.csv annotation_user5_kneel.csv user5\n",
      "input_user5_lie.csv annotation_user5_lie.csv user5\n",
      "input_user5_sit.csv annotation_user5_sit.csv user5\n",
      "input_user5_sitrotate.csv annotation_user5_sitrotate.csv user5\n",
      "input_user5_stand.csv annotation_user5_stand.csv user5\n",
      "input_user5_standrotate.csv annotation_user5_standrotate.csv user5\n",
      "input_user5_walking.csv annotation_user5_walking.csv user5\n",
      "input_user6_bendfwd.csv annotation_user6_bendfwd.csv user6\n",
      "input_user6_kneel.csv annotation_user6_kneel.csv user6\n",
      "input_user6_lie.csv annotation_user6_lie.csv user6\n",
      "input_user6_sit.csv annotation_user6_sit.csv user6\n",
      "input_user6_sitrotate.csv annotation_user6_sitrotate.csv user6\n",
      "input_user6_stand.csv annotation_user6_stand.csv user6\n",
      "input_user6_standrotate.csv annotation_user6_standrotate.csv user6\n",
      "input_user6_walking.csv annotation_user6_walking.csv user6\n",
      "input_user7_bendfwd.csv annotation_user7_bendfwd.csv user7\n",
      "input_user7_kneel.csv annotation_user7_kneel.csv user7\n",
      "input_user7_lie.csv annotation_user7_lie.csv user7\n",
      "input_user7_sit.csv annotation_user7_sit.csv user7\n",
      "input_user7_sitrotate.csv annotation_user7_sitrotate.csv user7\n",
      "input_user7_stand.csv annotation_user7_stand.csv user7\n",
      "input_user7_standrotate.csv annotation_user7_standrotate.csv user7\n",
      "input_user7_walking.csv annotation_user7_walking.csv user7\n",
      "input_user8_bendfwd.csv annotation_user8_bendfwd.csv user8\n",
      "input_user8_kneel.csv annotation_user8_kneel.csv user8\n",
      "input_user8_lie.csv annotation_user8_lie.csv user8\n",
      "input_user8_sit.csv annotation_user8_sit.csv user8\n",
      "input_user8_sitrotate.csv annotation_user8_sitrotate.csv user8\n",
      "input_user8_stand.csv annotation_user8_stand.csv user8\n",
      "input_user8_standrotate.csv annotation_user8_standrotate.csv user8\n",
      "input_user8_walking.csv annotation_user8_walking.csv user8\n",
      "input_user9_bendfwd.csv annotation_user9_bendfwd.csv user9\n",
      "input_user9_kneel.csv annotation_user9_kneel.csv user9\n",
      "input_user9_lie.csv annotation_user9_lie.csv user9\n",
      "input_user9_sit.csv annotation_user9_sit.csv user9\n",
      "input_user9_sitrotate.csv annotation_user9_sitrotate.csv user9\n",
      "input_user9_stand.csv annotation_user9_stand.csv user9\n",
      "input_user9_standrotate.csv annotation_user9_standrotate.csv user9\n",
      "input_user9_walking.csv annotation_user9_walking.csv user9\n"
     ]
    }
   ],
   "source": [
    "# 1. Import data\n",
    "fp = \"E:/external_data/Experiment3/csv_files/exp_1\"\n",
    "df = import_clean_data('exp_1',fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Process data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def seperate_dataframes(df):\n",
    "    features_ls,labels_ls = [],[]\n",
    "    for user in df['user'].unique():\n",
    "        dataframe = df[df['user']==user]\n",
    "        features = dataframe[[f'amp_{i}' for i in range(1,91)]].to_numpy()\n",
    "        features = MinMaxScaler().fit_transform(features)\n",
    "        features_ls.append(features)\n",
    "        label = dataframe[['label']].to_numpy()\n",
    "        labels_ls.append(label)\n",
    "    return features_ls,labels_ls\n",
    "\n",
    "\n",
    "X_ls, y_ls = seperate_dataframes(df)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasetobj(X,y):\n",
    "    datasetobj = DatasetObject()\n",
    "    datasetobj.import_data(X, y)\n",
    "    return datasetobj\n",
    "\n",
    "datasetobj = create_datasetobj(X_ls,y_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 arrays sizes ------ X:  (192, 3, 30, 900)  Y:  (192,)  Z:  (192, 1)\n",
      "index 1 arrays sizes ------ X:  (208, 3, 30, 900)  Y:  (208,)  Z:  (208, 1)\n",
      "index 2 arrays sizes ------ X:  (216, 3, 30, 900)  Y:  (216,)  Z:  (216, 1)\n",
      "index 3 arrays sizes ------ X:  (184, 3, 30, 900)  Y:  (184,)  Z:  (184, 1)\n",
      "index 4 arrays sizes ------ X:  (192, 3, 30, 900)  Y:  (192,)  Z:  (192, 1)\n",
      "index 5 arrays sizes ------ X:  (176, 3, 30, 900)  Y:  (176,)  Z:  (176, 1)\n",
      "index 6 arrays sizes ------ X:  (192, 3, 30, 900)  Y:  (192,)  Z:  (192, 1)\n",
      "index 7 arrays sizes ------ X:  (176, 3, 30, 900)  Y:  (176,)  Z:  (176, 1)\n",
      "index 8 arrays sizes ------ X:  (184, 3, 30, 900)  Y:  (184,)  Z:  (184, 1)\n",
      "index 9 arrays sizes ------ X:  (200, 3, 30, 900)  Y:  (200,)  Z:  (200, 1)\n",
      "size of DatasetObject ------ :  (10, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def transform_datasetobj(datasetobj):\n",
    "    window_size = 900\n",
    "    slide_size = 200\n",
    "    datasetobj.data_transform(lambda x,y,z : process_data.slide_augmentation(x, y, z,\n",
    "                                                                window_size=window_size,\n",
    "                                                                slide_size=slide_size,\n",
    "                                                                skip_labels=['noactivity']),axis=0)\n",
    "    datasetobj.data_transform(lambda arr: arr.reshape(-1,window_size,3,30).transpose(0,2,3,1),axis=1, col=0)\n",
    "    datasetobj.data_transform(lambda x,y,z : process_data.resampling(x, y, z, oversampling = True),axis=0)\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(datasetobj()[1])\n",
    "    datasetobj.data_transform(lambda arr: label_encoder.transform(arr).reshape(arr.shape),axis=1, col=1)\n",
    "    return datasetobj, label_encoder\n",
    "\n",
    "datasetobj, label_encoder = transform_datasetobj(datasetobj)\n",
    "datasetobj.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_ls, y_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: [0, 1, 2, 3, 4, 5, 6, 7, 8] \ttest set: [9]\n"
     ]
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def create_dataloaders(X_train, y_train, X_test, y_test, batch_sizes={'train':64, 'test':200}):\n",
    "    traindataset = TensorDataset(Tensor(X_train),Tensor(y_train).long())\n",
    "    testdataset = TensorDataset(Tensor(X_test), Tensor(y_test).long())\n",
    "    train_loader = DataLoader(traindataset, batch_size=batch_sizes['train'], shuffle=True, num_workers=4, drop_last=True)\n",
    "    test_loader = DataLoader(testdataset, batch_size=batch_sizes['test'], shuffle=True, num_workers=4)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "(X_train, y_train,_),(X_test, y_test,_) = datasetobj([9],return_train_sets=True)\n",
    "train_loader, test_loader = create_dataloaders(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.baseline import Lambda, Classifier,CNN_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model ,criterion , optimizer\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setting(model):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(list(model.parameters()), lr=0.0005)\n",
    "    return criterion, optimizer\n",
    "\n",
    "criterion, optimizer = setting(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n",
      "Start Training\n",
      "Epoch 1: >"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 4.00 GiB total capacity; 2.81 GiB already allocated; 28.84 MiB free; 2.85 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-8ae22aca5b52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m model = train(model, train_loader, criterion, optimizer, end = 300, start = 1, \n\u001b[1;32m---> 56\u001b[1;33m               test_loader = test_loader, parallel = True)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-8ae22aca5b52>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, criterion, optimizer, end, start, test_loader, parallel, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\">\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mloss\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Creator\\Script\\Python\\Project\\irs_toolbox\\models\\baseline.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-e68235bfa6d8>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-4b0b6c2e040c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\pooling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1002\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptive_max_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_adaptive_max_pool2d\u001b[1;34m(input, output_size, return_indices)\u001b[0m\n\u001b[0;32m    852\u001b[0m                 \u001b[0madaptive_max_pool2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m                 return_indices=return_indices)\n\u001b[1;32m--> 854\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0madaptive_max_pool2d_with_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m adaptive_max_pool2d = boolean_dispatch(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36madaptive_max_pool2d_with_indices\u001b[1;34m(input, output_size, return_indices)\u001b[0m\n\u001b[0;32m    842\u001b[0m                 return_indices=return_indices)\n\u001b[0;32m    843\u001b[0m     \u001b[0moutput_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_list_with_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 844\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptive_max_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 4.00 GiB total capacity; 2.81 GiB already allocated; 28.84 MiB free; 2.85 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, criterion, optimizer, end, start = 1, test_loader = None, parallel = None, **kwargs):\n",
    "\n",
    "    # Check device setting\n",
    "    if parallel == True:\n",
    "        print('GPU')\n",
    "        model = model.cuda()\n",
    "    else:\n",
    "        print('CPU')\n",
    "\n",
    "    print('Start Training')\n",
    "    record = {'train':[],'validation':[]}\n",
    "    i = start\n",
    "    #Loop\n",
    "    while i <= end:\n",
    "        print(f\"Epoch {i}: \", end='')\n",
    "        for b, (X_train, y_train) in enumerate(train_loader):\n",
    "            if parallel == True:\n",
    "                X_train, y_train = X_train.cuda(), y_train.cuda() #.to(device)\n",
    "            print(f\">\", end='')\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_train)\n",
    "            loss   = criterion(y_pred, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del X_train, y_train, y_pred\n",
    "        # One epoch completed\n",
    "        loss = loss.tolist()\n",
    "        record['train'].append(loss)\n",
    "        print(f' loss: {loss} ',end='')\n",
    "        if (test_loader != None) and i%10 ==0 :\n",
    "            acc = short_evaluation(model,test_loader,parallel)\n",
    "            record['validation'].append(acc)\n",
    "            print(f' accuracy: {acc}')\n",
    "        else:\n",
    "            print('')\n",
    "        i += 1\n",
    "\n",
    "    model = model.cpu()\n",
    "    return model, record\n",
    "\n",
    "def short_evaluation(model,test_loader,parallel):\n",
    "    # copy the model to cpu\n",
    "    if parallel == True:\n",
    "        model = model.cpu()\n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in test_loader:\n",
    "            y_val = model(X_test)\n",
    "            predicted = torch.max(y_val, 1)[1]\n",
    "            acc = accuracy_score(y_test.view(-1), predicted.view(-1))\n",
    "    # send model back to gpu\n",
    "    if parallel == True:\n",
    "        model = model.cuda()\n",
    "    return acc\n",
    "\n",
    "model = train(model, train_loader, criterion, optimizer, end = 300, start = 1, \n",
    "              test_loader = test_loader, parallel = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model,test_loader):\n",
    "    model = model.cpu()\n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in test_loader:\n",
    "            X_test, y_test = X_test, y_test\n",
    "            y_val = model(X_test)\n",
    "            predicted = torch.max(y_val, 1)[1]\n",
    "    cls = classification_report(y_test.view(-1), predicted.view(-1), output_dict=True)\n",
    "    cls = pd.DataFrame(cls)\n",
    "    print(cls)\n",
    "    cmtx = confusion_matrix(y_test.view(-1), predicted.view(-1))\n",
    "    return cmtx,cls\n",
    "\n",
    "def cmtx_table(cmtx,label_encoder=None):\n",
    "    if label_encoder != None:\n",
    "        cmtx = pd.DataFrame(cmtx,\n",
    "                            index=[f\"actual: {i}\"for i in label_encoder.categories_[0].tolist()], \n",
    "                            columns=[f\"predict : {i}\"for i in label_encoder.categories_[0].tolist()])\n",
    "    else: \n",
    "        cmtx = pd.DataFrame(cmtx)\n",
    "    return cmtx\n",
    "\n",
    "cmtx,cls = evaluation(model,test_loader)\n",
    "cmtx = cmtx_table(cmtx,label_encoder=None)\n",
    "cmtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = pd.DataFrame(record['train'],columns=['train_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.train import save_checkpoint, make_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = make_directory('V2cSimCLR',epoch=500,filepath='./record/')\n",
    "train_loss.to_csv(path+'_loss.csv')\n",
    "# cls.to_csv(path+'_report.csv')\n",
    "# cmtx.to_csv(path+'_cmtx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = make_directory('V2cSimCLR_pretrain',epoch=500)\n",
    "save_checkpoint(model, optimizer, 500, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
