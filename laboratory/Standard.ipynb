{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from time import gmtime, strftime\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import poutyne\n",
    "from poutyne import Model,Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.custom_data import filepath_dataframe\n",
    "from data.selection import Selection\n",
    "from data.transformation import Transform_CnnLstmS,Transform_CnnS\n",
    "from data.torchData import DataLoadings,DataLoading\n",
    "\n",
    "from data.custom_data import nucPaired_fpDataframe\n",
    "from data.torchData import PairDataLoading,DataLoading\n",
    "from training.contrastive_pretraining import Contrastive_PreTraining\n",
    "from training.finetuning import FineTuneCNN\n",
    "\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Name:  AlexNet_Supervised_EXP7-NUC1-Room1-Amp-RandomSplit-ResReduced_Comment-TestLoov\n",
      "Cuda Availability:  True\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################################################\n",
    "\n",
    "# random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# gpu setting\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(DEVICE)\n",
    "device = DEVICE\n",
    "\n",
    "## data directory\n",
    "data_dir  = 'E:\\\\external_data\\\\opera_csi\\\\Session_2\\\\experiment_data\\\\experiment_data\\\\exp_7_amp_spec_only\\\\npy_format'\n",
    "readtype = 'npy'\n",
    "splitchar = '\\\\'\n",
    "fpath = '.'\n",
    "\n",
    "# data selection\n",
    "dataselection_name = 'EXP7-NUC1-Room1-Amp-RandomSplit-ResReduced'\n",
    "\n",
    "data_selection = Selection(split='random',test_sub=0.2,val_sub=0.1,\n",
    "                           nuc='NUC1',room=1,sample_per_class=None)\n",
    "\n",
    "# data loading\n",
    "transform = Transform_CnnS()\n",
    "batch_size = 64\n",
    "num_workers = 0\n",
    "\n",
    "# training\n",
    "optimizer_builder = torch.optim.SGD\n",
    "lr = 0.001\n",
    "pretrain_epochs = 1\n",
    "finetune_epochs = 1\n",
    "\n",
    "# model\n",
    "builder = models.cnn.create_alexnet\n",
    "network_name = 'AlexNet'\n",
    "\n",
    "# Experiment Name\n",
    "comment = 'TestLoov'\n",
    "exp_name = f'{network_name}_Supervised_{dataselection_name}_Comment-{comment}'\n",
    "\n",
    "# auto\n",
    "record_dir = os.path.join(fpath,'record')\n",
    "model_dir = os.path.join(fpath,'saved_model')\n",
    "model_fname = os.path.join(model_dir,f'Encoder___{exp_name}')\n",
    "print('Experiment Name: ',exp_name)\n",
    "print('Cuda Availability: ',torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------Main-------------------------------------------\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "# data preparation\n",
    "df = filepath_dataframe(data_dir,splitchar)\n",
    "df_train,df_val,df_test = data_selection(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FINE-TUNING #####\n",
    "\n",
    "# data loading\n",
    "data_loading = DataLoading(transform=transform,batch_size=batch_size,readtype=readtype,\n",
    "                           num_workers=num_workers,drop_last=True)\n",
    "test_loading = DataLoading(transform=transform,batch_size=len(df_test),readtype=readtype,\n",
    "                           num_workers=num_workers,drop_last=True)\n",
    "\n",
    "train_loader = data_loading(df_train)\n",
    "val_loader   = data_loading(df_val)\n",
    "test_loader  = test_loading(df_test)\n",
    "\n",
    "# load and create model\n",
    "model = FineTuneCNN(model_path=None,\n",
    "                    encoder_builder=builder,\n",
    "                    n_classes=df.activity.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "             Stack-1          [-1, 3, 70, 1600]               0\n",
      "UpsamplingNearest2d-2          [-1, 3, 70, 1600]               0\n",
      "            Conv2d-3          [-1, 64, 16, 399]          23,296\n",
      "              ReLU-4          [-1, 64, 16, 399]               0\n",
      "         MaxPool2d-5           [-1, 64, 7, 199]               0\n",
      "            Conv2d-6          [-1, 192, 7, 199]         307,392\n",
      "              ReLU-7          [-1, 192, 7, 199]               0\n",
      "         MaxPool2d-8           [-1, 192, 3, 99]               0\n",
      "            Conv2d-9           [-1, 384, 3, 99]         663,936\n",
      "             ReLU-10           [-1, 384, 3, 99]               0\n",
      "           Conv2d-11           [-1, 256, 3, 99]         884,992\n",
      "             ReLU-12           [-1, 256, 3, 99]               0\n",
      "           Conv2d-13           [-1, 256, 3, 99]         590,080\n",
      "             ReLU-14           [-1, 256, 3, 99]               0\n",
      "        MaxPool2d-15           [-1, 256, 1, 49]               0\n",
      "AdaptiveAvgPool2d-16            [-1, 256, 2, 2]               0\n",
      "          Flatten-17                 [-1, 1024]               0\n",
      "           Linear-18                  [-1, 128]         131,200\n",
      "        LeakyReLU-19                  [-1, 128]               0\n",
      "          Dropout-20                  [-1, 128]               0\n",
      "           Linear-21                    [-1, 6]             774\n",
      "       Classifier-22                    [-1, 6]               0\n",
      "================================================================\n",
      "Total params: 2,601,670\n",
      "Trainable params: 2,601,670\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.43\n",
      "Forward/backward pass size (MB): 20.73\n",
      "Params size (MB): 9.92\n",
      "Estimated Total Size (MB): 31.08\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model,(1,70,1600),device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "\u001b[35mEpoch: \u001b[36m1/1 \u001b[35mStep: \u001b[36m26/26 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m38.09s \u001b[35mloss:\u001b[94m 447.651918\u001b[35m acc:\u001b[94m 31.506849\u001b[35m fscore_micro:\u001b[94m 0.315068\u001b[35m fscore_macro:\u001b[94m 0.151575\u001b[35m val_loss:\u001b[94m 1.791747\u001b[35m val_acc:\u001b[94m 16.666668\u001b[35m val_fscore_micro:\u001b[94m 0.166667\u001b[35m val_fscore_macro:\u001b[94m 0.047619\u001b[0m\n",
      "loss                447.651918\n",
      "time                 38.094241\n",
      "acc                  31.506849\n",
      "fscore_micro          0.315068\n",
      "fscore_macro          0.151575\n",
      "val_loss              1.791747\n",
      "val_acc              16.666668\n",
      "val_fscore_micro      0.166667\n",
      "val_fscore_macro      0.047619\n",
      "Name: 0, dtype: float64 \n",
      "\n",
      "Two\n",
      "\u001b[35mEpoch: \u001b[36m1/1 \u001b[35mStep: \u001b[36m25/25 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m37.71s \u001b[35mloss:\u001b[94m 276.575657\u001b[35m acc:\u001b[94m 43.837357\u001b[35m fscore_micro:\u001b[94m 0.438374\u001b[35m fscore_macro:\u001b[94m 0.190038\u001b[35m val_loss:\u001b[94m 1.792224\u001b[35m val_acc:\u001b[94m 16.666668\u001b[35m val_fscore_micro:\u001b[94m 0.166667\u001b[35m val_fscore_macro:\u001b[94m 0.047619\u001b[0m\n",
      "loss                276.575657\n",
      "time                 37.713494\n",
      "acc                  43.837357\n",
      "fscore_micro          0.438374\n",
      "fscore_macro          0.190038\n",
      "val_loss              1.792224\n",
      "val_acc              16.666668\n",
      "val_fscore_micro      0.166667\n",
      "val_fscore_macro      0.047619\n",
      "Name: 0, dtype: float64 \n",
      "\n",
      "Three\n",
      "\u001b[35mEpoch: \u001b[36m1/1 \u001b[35mStep: \u001b[36m22/22 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m35.30s \u001b[35mloss:\u001b[94m 687.670410\u001b[35m acc:\u001b[94m 32.591529\u001b[35m fscore_micro:\u001b[94m 0.325915\u001b[35m fscore_macro:\u001b[94m 0.081935\u001b[35m val_loss:\u001b[94m 1.792861\u001b[35m val_acc:\u001b[94m 16.666668\u001b[35m val_fscore_micro:\u001b[94m 0.166667\u001b[35m val_fscore_macro:\u001b[94m 0.047619\u001b[0m\n",
      "loss                687.670410\n",
      "time                 35.300305\n",
      "acc                  32.591529\n",
      "fscore_micro          0.325915\n",
      "fscore_macro          0.081935\n",
      "val_loss              1.792861\n",
      "val_acc              16.666668\n",
      "val_fscore_micro      0.166667\n",
      "val_fscore_macro      0.047619\n",
      "Name: 0, dtype: float64 \n",
      "\n",
      "Four\n",
      "\u001b[35mEpoch: \u001b[36m1/1 \u001b[35mStep: \u001b[36m27/27 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m40.00s \u001b[35mloss:\u001b[94m 1374.277292\u001b[35m acc:\u001b[94m 38.488372\u001b[35m fscore_micro:\u001b[94m 0.384884\u001b[35m fscore_macro:\u001b[94m 0.206145\u001b[35m val_loss:\u001b[94m 1.793488\u001b[35m val_acc:\u001b[94m 16.666668\u001b[35m val_fscore_micro:\u001b[94m 0.166667\u001b[35m val_fscore_macro:\u001b[94m 0.047619\u001b[0m\n",
      "loss                1374.277292\n",
      "time                  40.000762\n",
      "acc                   38.488372\n",
      "fscore_micro           0.384884\n",
      "fscore_macro           0.206145\n",
      "val_loss               1.793488\n",
      "val_acc               16.666668\n",
      "val_fscore_micro       0.166667\n",
      "val_fscore_macro       0.047619\n",
      "Name: 0, dtype: float64 \n",
      "\n",
      "Five\n",
      "\u001b[35mEpoch: \u001b[36m1/1 \u001b[35mStep: \u001b[36m25/25 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m38.41s \u001b[35mloss:\u001b[94m 873.969257\u001b[35m acc:\u001b[94m 25.429116\u001b[35m fscore_micro:\u001b[94m 0.254291\u001b[35m fscore_macro:\u001b[94m 0.102881\u001b[35m val_loss:\u001b[94m 1.792153\u001b[35m val_acc:\u001b[94m 16.666668\u001b[35m val_fscore_micro:\u001b[94m 0.166667\u001b[35m val_fscore_macro:\u001b[94m 0.047619\u001b[0m\n",
      "loss                873.969257\n",
      "time                 38.414563\n",
      "acc                  25.429116\n",
      "fscore_micro          0.254291\n",
      "fscore_macro          0.102881\n",
      "val_loss              1.792153\n",
      "val_acc              16.666668\n",
      "val_fscore_micro      0.166667\n",
      "val_fscore_macro      0.047619\n",
      "Name: 0, dtype: float64 \n",
      "\n",
      "Six\n",
      "\u001b[35mEpoch: \u001b[36m1/1 \u001b[35mStep: \u001b[36m25/25 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m39.91s \u001b[35mloss:\u001b[94m 479.837123\u001b[35m acc:\u001b[94m 27.329581\u001b[35m fscore_micro:\u001b[94m 0.273296\u001b[35m fscore_macro:\u001b[94m 0.103017\u001b[35m val_loss:\u001b[94m 1.791377\u001b[35m val_acc:\u001b[94m 16.666668\u001b[35m val_fscore_micro:\u001b[94m 0.166667\u001b[35m val_fscore_macro:\u001b[94m 0.047619\u001b[0m\n",
      "loss                479.837123\n",
      "time                 39.914294\n",
      "acc                  27.329581\n",
      "fscore_micro          0.273296\n",
      "fscore_macro          0.103017\n",
      "val_loss              1.791377\n",
      "val_acc              16.666668\n",
      "val_fscore_micro      0.166667\n",
      "val_fscore_macro      0.047619\n",
      "Name: 0, dtype: float64 \n",
      "\n",
      "Seven\n",
      "Skip Seven\n"
     ]
    }
   ],
   "source": [
    "# train with poutyne\n",
    "mdl = Model(model,'adam','cross_entropy',\n",
    "            batch_metrics=['accuracy'],\n",
    "            epoch_metrics=[poutyne.F1('micro'),poutyne.F1('macro')]).to(device)\n",
    "history = mdl.fit_generator(train_generator=train_loader,valid_generator=test_loader,epochs=finetune_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
