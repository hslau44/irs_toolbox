{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from time import gmtime, strftime\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import poutyne\n",
    "from poutyne import Model,Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.custom_data import filepath_dataframe,nucPaired_fpDataframe\n",
    "from data.selection import Selection,SelectionSet_1\n",
    "from data.transformation import Transform_CnnLstmS,Transform_CnnS\n",
    "from data.torchData import DataLoadings,DataLoading,PairDataLoading\n",
    "\n",
    "from data.custom_data import nucPaired_fpDataframe\n",
    "from data.torchData import PairDataLoading,DataLoading\n",
    "from training.contrastive_pretraining import Contrastive_PreTraining\n",
    "from training.finetuning import FineTuneCNN\n",
    "\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Name:  ConvNet1D_NTXent_SelectionSet1_Comment-3LayerDefault\n",
      "Cuda Availability:  True\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################################################\n",
    "\n",
    "# random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# gpu setting\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(DEVICE)\n",
    "device = DEVICE\n",
    "\n",
    "## data directory\n",
    "data_dir  = 'E:\\\\external_data\\\\opera_csi\\\\Session_2\\\\experiment_data\\\\experiment_data\\\\exp_7_amp_spec_only\\\\npy_format'\n",
    "readtype = 'npy'\n",
    "splitchar = '\\\\'\n",
    "fpath = '.'\n",
    "\n",
    "# data selection\n",
    "data_selection = SelectionSet_1() # Selection(split='random',test_sub=0.2,val_sub=0.1,nuc='NUC1',room=1,sample_per_class=None)\n",
    "dataselection_name = 'SelectionSet1' # 'EXP7-NUC1-Room1-Amp-RandomSplit-ResReduced'\n",
    "\n",
    "# data loading\n",
    "transform = None\n",
    "batch_size = 128\n",
    "num_workers = 0\n",
    "\n",
    "# training\n",
    "optimizer_builder = torch.optim.SGD\n",
    "lr = 0.0005\n",
    "pretrain_epochs = 800\n",
    "finetune_epochs = 200\n",
    "supervision = None\n",
    "temperature = 0.5\n",
    "\n",
    "# model\n",
    "builder = lambda : (models.baseline.ConvNet1D(strides=[16,8,4]), 6144)\n",
    "hidden_layer = 128\n",
    "network_name = 'ConvNet1D'\n",
    "\n",
    "# Experiment Name\n",
    "comment = '3LayerDefault'\n",
    "exp_name = f'{network_name}_NTXent_{dataselection_name}_Comment-{comment}'\n",
    "\n",
    "# auto\n",
    "record_dir = os.path.join(fpath,'record')\n",
    "model_dir = os.path.join(fpath,'saved_model')\n",
    "model_fname = os.path.join(model_dir,f'Encoder___{exp_name}')\n",
    "print('Experiment Name: ',exp_name)\n",
    "print('Cuda Availability: ',torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------Main-------------------------------------------\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "# data preparation\n",
    "df = filepath_dataframe(data_dir,splitchar)\n",
    "df = nucPaired_fpDataframe(df)\n",
    "df_train,df_val,df_test = data_selection(df)\n",
    "df_train = pd.concat([df_train,df_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_loading = PairDataLoading(transform=transform,\n",
    "                                   batch_size=batch_size,\n",
    "                                   readtype=readtype,\n",
    "                                   supervision=True,\n",
    "                                   num_workers=num_workers,\n",
    "                                   drop_last=True)\n",
    "\n",
    "\n",
    "pretrain_loader = pretrain_loading(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 >>>>>>>>>>>> loss: 2.7818081378936768\n",
      "Epoch 2 >>>>>>>>>>>> loss: 2.7762794494628906\n",
      "Epoch 3 >>>>>>>>>>>> loss: 2.7711148262023926\n",
      "Epoch 4 >>>>>>>>>>>> loss: 2.7711105346679688\n",
      "Epoch 5 >>>>>>>>>>>> loss: 2.7704267501831055\n",
      "Epoch 6 >>>>>>>>>>>> loss: 2.7703018188476562\n",
      "Epoch 7 >>>>>>>>>>>> loss: 2.7699735164642334\n",
      "Epoch 8 >>>>>>>>>>>> loss: 2.769225835800171\n",
      "Epoch 9 >>>>>>>>>>>> loss: 2.768512487411499\n",
      "Epoch 10 >>>>>>>>>>>> loss: 2.76670503616333\n",
      "Epoch 11 >>>>>>>>>>>> loss: 2.7694859504699707\n",
      "Epoch 12 >>>>>>>>>>>> loss: 2.7599620819091797\n",
      "Epoch 13 >>>>>>>>>>>> loss: 2.7359790802001953\n",
      "Epoch 14 >>>>>>>>>>>> loss: 2.7215702533721924\n",
      "Epoch 15 >>>>>>>>>>>> loss: 2.6975810527801514\n",
      "Epoch 16 >>>>>>>>>>>> loss: 2.7277119159698486\n",
      "Epoch 17 >>>>>>>>>>>> loss: 2.6771163940429688\n",
      "Epoch 18 >>>>>>>>>>>> loss: 2.681680202484131\n",
      "Epoch 19 >>>>>>>>>>>> loss: 2.6459248065948486\n",
      "Epoch 20 >>>>>>>>>>>> loss: 2.6554291248321533\n",
      "Epoch 21 >>>>>>>>>>>> loss: 2.6789443492889404\n",
      "Epoch 22 >>>>>>>>>>>> loss: 2.635526657104492\n",
      "Epoch 23 >>>>>>>>>>>> loss: 2.5843541622161865\n",
      "Epoch 24 >>>>>>>>>>>> loss: 2.54404354095459\n",
      "Epoch 25 >>>>>>>>>>>> loss: 2.526205062866211\n",
      "Epoch 26 >>>>>>>>>>>> loss: 2.533888101577759\n",
      "Epoch 27 >>>>>>>>>>>> loss: 2.4950292110443115\n",
      "Epoch 28 >>>>>>>>>>>> loss: 2.524343490600586\n",
      "Epoch 29 >>>>>>>>>>>> loss: 2.4720561504364014\n",
      "Epoch 30 >>>>>>>>>>>> loss: 2.395714282989502\n",
      "Epoch 31 >>>>>>>>>>>> loss: 2.4314463138580322\n",
      "Epoch 32 >>>>>>>>>>>> loss: 2.3763513565063477\n",
      "Epoch 33 >>>>>>>>>>>> loss: 2.370410203933716\n",
      "Epoch 34 >>>>>>>>>>>> loss: 2.433049201965332\n",
      "Epoch 35 >>>>>>>>>>>> loss: 2.445582389831543\n",
      "Epoch 36 >>>>>>>>>>>> loss: 2.3995118141174316\n",
      "Epoch 37 >>>>>>>>>>>> loss: 2.3385109901428223\n",
      "Epoch 38 >>>>>>>>>>>> loss: 2.3449840545654297\n",
      "Epoch 39 >>>>>>>>>>>> loss: 2.332324504852295\n",
      "Epoch 40 >>>>>>>>>>>> loss: 2.2949695587158203\n",
      "Epoch 41 >>>>>>>>>>>> loss: 2.335509777069092\n",
      "Epoch 42 >>>>>>>>>>>> loss: 2.269437313079834\n",
      "Epoch 43 >>>>>>>>>>>> loss: 2.2775888442993164\n",
      "Epoch 44 >>>>>>>>>>>> loss: 2.2326130867004395\n",
      "Epoch 45 >>>>>>>>>>>> loss: 2.256584644317627\n",
      "Epoch 46 >>>>>>>>>>>> loss: 2.271336555480957\n",
      "Epoch 47 >>>>>>>>>>>> loss: 2.2379307746887207\n",
      "Epoch 48 >>>>>>>>>>>> loss: 2.273796796798706\n",
      "Epoch 49 >>>>>>>>>>>> loss: 2.2597403526306152\n",
      "Epoch 50 >>>>>>>>>>>> loss: 2.2223501205444336\n",
      "Epoch 51 >>>>>>>>>>>> loss: 2.223463535308838\n",
      "Epoch 52 >>>>>>>>>>>> loss: 2.2445664405822754\n",
      "Epoch 53 >>>>>>>>>>>> loss: 2.2287349700927734\n",
      "Epoch 54 >>>>>>>>>>>> loss: 2.237177610397339\n",
      "Epoch 55 >>>>>>>>>>>> loss: 2.214357852935791\n",
      "Epoch 56 >>>>>>>>>>>> loss: 2.164827346801758\n",
      "Epoch 57 >>>>>>>>>>>> loss: 2.162003993988037\n",
      "Epoch 58 >>>>>>>>>>>> loss: 2.147228717803955\n",
      "Epoch 59 >>>>>>>>>>>> loss: 2.1621665954589844\n",
      "Epoch 60 >>>>>>>>>>>> loss: 2.160055637359619\n",
      "Epoch 61 >>>>>>>>>>>> loss: 2.2000985145568848\n",
      "Epoch 62 >>>>>>>>>>>> loss: 2.13331937789917\n",
      "Epoch 63 >>>>>>>>>>>> loss: 2.151956558227539\n",
      "Epoch 64 >>>>>>>>>>>> loss: 2.1739206314086914\n",
      "Epoch 65 >>>>>>>>>>>> loss: 2.1603899002075195\n",
      "Epoch 66 >>>>>>>>>>>> loss: 2.149892807006836\n",
      "Epoch 67 >>>>>>>>>>>> loss: 2.1582274436950684\n",
      "Epoch 68 >>>>>>>>>>>> loss: 2.1588401794433594\n",
      "Epoch 69 >>>>>>>>>>>> loss: 2.124760627746582\n",
      "Epoch 70 >>>>>>>>>>>> loss: 2.142730474472046\n",
      "Epoch 71 >>>>>>>>>>>> loss: 2.1287107467651367\n",
      "Epoch 72 >>>>>>>>>>>> loss: 2.122945785522461\n",
      "Epoch 73 >>>>>>>>>>>> loss: 2.1012256145477295\n",
      "Epoch 74 >>>>>>>>>>>> loss: 2.0848255157470703\n",
      "Epoch 75 >>>>>>>>>>>> loss: 2.0918827056884766\n",
      "Epoch 76 >>>>>>>>>>>> loss: 2.105901002883911\n",
      "Epoch 77 >>>>>>>>>>>> loss: 2.0881881713867188\n",
      "Epoch 78 >>>>>>>>>>>> loss: 2.092252254486084\n",
      "Epoch 79 >>>>>>>>>>>> loss: 2.0949368476867676\n",
      "Epoch 80 >>>>>>>>>>>> loss: 2.094848155975342\n",
      "Epoch 81 >>>>>>>>>>>> loss: 2.08477783203125\n",
      "Epoch 82 >>>>>>>>>>>> loss: 2.0709311962127686\n",
      "Epoch 83 >>>>>>>>>>>> loss: 2.086966037750244\n",
      "Epoch 84 >>>>>>>>>>>> loss: 2.0782055854797363\n",
      "Epoch 85 >>>>>>>>>>>> loss: 2.088186740875244\n",
      "Epoch 86 >>>>>>>>>>>> loss: 2.088111639022827\n",
      "Epoch 87 >>>>>>>>>>>> loss: 2.067753791809082\n",
      "Epoch 88 >>>>>>>>>>>> loss: 2.078314781188965\n",
      "Epoch 89 >>>>>>>>>>>> loss: 2.0821139812469482\n",
      "Epoch 90 >>>>>>>>>>>> loss: 2.0704469680786133\n",
      "Epoch 91 >>>>>>>>>>>> loss: 2.0637319087982178\n",
      "Epoch 92 >>>>>>>>>>>> loss: 2.0560882091522217\n",
      "Epoch 93 >>>>>>>>>>>> loss: 2.057201623916626\n",
      "Epoch 94 >>>>>>>>>>>> loss: 2.0581531524658203\n",
      "Epoch 95 >>>>>>>>>>>> loss: 2.05692982673645\n",
      "Epoch 96 >>>>>>>>>>>> loss: 2.0476412773132324\n",
      "Epoch 97 >>>>>>>>>>>> loss: 2.0560851097106934\n",
      "Epoch 98 >>>>>>>>>>>> loss: 2.068586587905884\n",
      "Epoch 99 >>>>>>>>>>>> loss: 2.0654869079589844\n",
      "Epoch 100 >>>>>>>>>>>> loss: 2.051887035369873\n",
      "Epoch 101 >>>>>>>>>>>> loss: 2.048429489135742\n",
      "Epoch 102 >>>>>>>>>>>> loss: 2.057823896408081\n",
      "Epoch 103 >>>>>>>>>>>> loss: 2.0673892498016357\n",
      "Epoch 104 >>>>>>>>>>>> loss: 2.0535058975219727\n",
      "Epoch 105 >>>>>>>>>>>> loss: 2.033785820007324\n",
      "Epoch 106 >>>>>>>>>>>> loss: 2.0326216220855713\n",
      "Epoch 107 >>>>>>>>>>>> loss: 2.025855541229248\n",
      "Epoch 108 >>>>>>>>>>>> loss: 2.02026104927063\n",
      "Epoch 109 >>>>>>>>>>>> loss: 2.0213167667388916\n",
      "Epoch 110 >>>>>>>>>>>> loss: 2.031550168991089\n",
      "Epoch 111 >>>>>>>>>>>> loss: 2.0263047218322754\n",
      "Epoch 112 >>>>>>>>>>>> loss: 2.041490077972412\n",
      "Epoch 113 >>>>>>>>>>>> loss: 2.024205207824707\n",
      "Epoch 114 >>>>>>>>>>>> loss: 2.016310214996338\n",
      "Epoch 115 >>>>>>>>>>>> loss: 2.045316219329834\n",
      "Epoch 116 >>>>>>>>>>>> loss: 2.015878677368164\n",
      "Epoch 117 >>>>>>>>>>>> loss: 2.013597249984741\n",
      "Epoch 118 >>>>>>>>>>>> loss: 2.0231571197509766\n",
      "Epoch 119 >>>>>>>>>>>> loss: 2.030662775039673\n",
      "Epoch 120 >>>>>>>>>>>> loss: 2.018907070159912\n",
      "Epoch 121 >>>>>>>>>>>> loss: 2.0164406299591064\n",
      "Epoch 122 >>>>>>>>>>>> loss: 2.011401414871216\n",
      "Epoch 123 >>>>>>>>>>>> loss: 2.0030224323272705\n",
      "Epoch 124 >>>>>>>>>>>> loss: 2.0043785572052\n",
      "Epoch 125 >>>>>>>>>>>> loss: 2.001641273498535\n",
      "Epoch 126 >>>>>>>>>>>> loss: 2.026362180709839\n",
      "Epoch 127 >>>>>>>>>>>> loss: 2.012956142425537\n",
      "Epoch 128 >>>>>>>>>>>> loss: 1.9999667406082153\n",
      "Epoch 129 >>>>>>>>>>>> loss: 2.0190396308898926\n",
      "Epoch 130 >>>>>>>>>>>> loss: 2.0043396949768066\n",
      "Epoch 131 >>>>>>>>>>>> loss: 2.025041341781616\n",
      "Epoch 132 >>>>>>>>>>>> loss: 2.003742218017578\n",
      "Epoch 133 >>>>>>>>>>>> loss: 2.0059566497802734\n",
      "Epoch 134 >>>>>>>>>>>> loss: 1.9928141832351685\n",
      "Epoch 135 >>>>>>>>>>>> loss: 1.9971535205841064\n",
      "Epoch 136 >>>>>>>>>>>> loss: 1.9944745302200317\n",
      "Epoch 137 >>>>>>>>>>>> loss: 1.996073842048645\n",
      "Epoch 138 >>>>>>>>>>>> loss: 1.9911385774612427\n",
      "Epoch 139 >>>>>>>>>>>> loss: 1.978130578994751\n",
      "Epoch 140 >>>>>>>>>>>> loss: 1.987492561340332\n",
      "Epoch 141 >>>>>>>>>>>> loss: 1.985788106918335\n",
      "Epoch 142 >>>>>>>>>>>> loss: 1.9807922840118408\n",
      "Epoch 143 >>>>>>>>>>>> loss: 1.9941823482513428\n",
      "Epoch 144 >>>>>>>>>>>> loss: 1.9717811346054077\n",
      "Epoch 145 >>>>>>>>>>>> loss: 1.982722282409668\n",
      "Epoch 146 >>>>>>>>>>>> loss: 1.9917290210723877\n",
      "Epoch 147 >>>>>>>>>>>> loss: 1.9768848419189453\n",
      "Epoch 148 >>>>>>>>>>>> loss: 1.9860179424285889\n",
      "Epoch 149 >>>>>>>>>>>> loss: 2.0022740364074707\n",
      "Epoch 150 >>>>>>>>>>>> loss: 1.9923622608184814\n",
      "Epoch 151 >>>>>>>>>>>> loss: 1.9920271635055542\n",
      "Epoch 152 >>>>>>>>>>>> loss: 1.9796218872070312\n",
      "Epoch 153 >>>>>>>>>>>> loss: 1.9845833778381348\n",
      "Epoch 154 >>>>>>>>>>>> loss: 1.9877073764801025\n",
      "Epoch 155 >>>>>>>>>>>> loss: 1.9779906272888184\n",
      "Epoch 156 >>>>>>>>>>>> loss: 1.98311448097229\n",
      "Epoch 157 >>>>>>>>>>>> loss: 1.9786491394042969\n",
      "Epoch 158 >>>>>>>>>>>> loss: 1.9793064594268799\n",
      "Epoch 159 >>>>>>>>>>>> loss: 1.9826935529708862\n",
      "Epoch 160 >>>>>>>>>>>> loss: 1.9696375131607056\n",
      "Epoch 161 >>>>>>>>>>>> loss: 1.9632220268249512\n",
      "Epoch 162 >>>>>>>>>>>> loss: 1.9764273166656494\n",
      "Epoch 163 >>>>>>>>>>>> loss: 1.9666900634765625\n",
      "Epoch 164 >>>>>>>>>>>> loss: 1.96725594997406\n",
      "Epoch 165 >>>>>>>>>>>> loss: 1.9733481407165527\n",
      "Epoch 166 >>>>>>>>>>>> loss: 1.9691753387451172\n",
      "Epoch 167 >>>>>>>>>>>> loss: 1.9650447368621826\n",
      "Epoch 168 >>>>>>>>>>>> loss: 1.9704018831253052\n",
      "Epoch 169 >>>>>>>>>>>> loss: 1.974513053894043\n",
      "Epoch 170 >>>>>>>>>>>> loss: 1.9604878425598145\n",
      "Epoch 171 >>>>>>>>>>>> loss: 1.9603651762008667\n",
      "Epoch 172 >>>>>>>>>>>> loss: 1.9588444232940674\n",
      "Epoch 173 >>>>>>>>>>>> loss: 1.954453945159912\n",
      "Epoch 174 >>>>>>>>>>>> loss: 1.9524405002593994\n",
      "Epoch 175 >>>>>>>>>>>> loss: 1.951095700263977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176 >>>>>>>>>>>> loss: 1.9515788555145264\n",
      "Epoch 177 >>>>>>>>>>>> loss: 1.9466173648834229\n",
      "Epoch 178 >>>>>>>>>>>> loss: 1.9599907398223877\n",
      "Epoch 179 >>>>>>>>>>>> loss: 1.971801519393921\n",
      "Epoch 180 >>>>>>>>>>>> loss: 1.9512381553649902\n",
      "Epoch 181 >>>>>>>>>>>> loss: 1.973233938217163\n",
      "Epoch 182 >>>>>>>>>>>> loss: 1.9542412757873535\n",
      "Epoch 183 >>>>>>>>>>>> loss: 1.9645557403564453\n",
      "Epoch 184 >>>>>>>>>>>> loss: 1.962028980255127\n",
      "Epoch 185 >>>>>>>>>>>> loss: 1.9458078145980835\n",
      "Epoch 186 >>>>>>>>>>>> loss: 1.9521450996398926\n",
      "Epoch 187 >>>>>>>>>>>> loss: 1.9478600025177002\n",
      "Epoch 188 >>>>>>>>>>>> loss: 1.9446121454238892\n",
      "Epoch 189 >>>>>>>>>>>> loss: 1.9481627941131592\n",
      "Epoch 190 >>>>>>>>>>>> loss: 1.9548943042755127\n",
      "Epoch 191 >>>>>>>>>>>> loss: 1.9440782070159912\n",
      "Epoch 192 >>>>>>>>>>>> loss: 1.9608967304229736\n",
      "Epoch 193 >>>>>>>>>>>> loss: 1.955028772354126\n",
      "Epoch 194 >>>>>>>>>>>> loss: 1.9521421194076538\n",
      "Epoch 195 >>>>>>>>>>>> loss: 1.9596457481384277\n",
      "Epoch 196 >>>>>>>>>>>> loss: 1.9672431945800781\n",
      "Epoch 197 >>>>>>>>>>>> loss: 1.9504613876342773\n",
      "Epoch 198 >>>>>>>>>>>> loss: 1.9576642513275146\n",
      "Epoch 199 >>>>>>>>>>>> loss: 1.9628853797912598\n",
      "Epoch 200 >>>>>>>>>>>> loss: 1.9508919715881348\n",
      "Epoch 201 >>>>>>>>>>>> loss: 1.9508886337280273\n",
      "Epoch 202 >>>>>>>>>>>> loss: 1.9526212215423584\n",
      "Epoch 203 >>>>>>>>>>>> loss: 1.946062684059143\n",
      "Epoch 204 >>>>>>>>>>>> loss: 1.9442222118377686\n",
      "Epoch 205 >>>>>>>>>>>> loss: 1.9352295398712158\n",
      "Epoch 206 >>>>>>>>>>>> loss: 1.9345178604125977\n",
      "Epoch 207 >>>>>>>>>>>> loss: 1.9360032081604004\n",
      "Epoch 208 >>>>>>>>>>>> loss: 1.9451148509979248\n",
      "Epoch 209 >>>>>>>>>>>> loss: 1.9408422708511353\n",
      "Epoch 210 >>>>>>>>>>>> loss: 1.9305415153503418\n",
      "Epoch 211 >>>>>>>>>>>> loss: 1.9423573017120361\n",
      "Epoch 212 >>>>>>>>>>>> loss: 1.9384651184082031\n",
      "Epoch 213 >>>>>>>>>>>> loss: 1.9429399967193604\n",
      "Epoch 214 >>>>>>>>>>>> loss: 1.9301342964172363\n",
      "Epoch 215 >>>>>>>>>>>> loss: 1.9309282302856445\n",
      "Epoch 216 >>>>>>>>>>>> loss: 1.9342767000198364\n",
      "Epoch 217 >>>>>>>>>>>> loss: 1.9395365715026855\n",
      "Epoch 218 >>>>>>>>>>>> loss: 1.9375813007354736\n",
      "Epoch 219 >>>>>>>>>>>> loss: 1.9410052299499512\n",
      "Epoch 220 >>>>>>>>>>>> loss: 1.9362322092056274\n",
      "Epoch 221 >>>>>>>>>>>> loss: 1.944387435913086\n",
      "Epoch 222 >>>>>>>>>>>> loss: 1.9390486478805542\n",
      "Epoch 223 >>>>>>>>>>>> loss: 1.9392199516296387\n",
      "Epoch 224 >>>>>>>>>>>> loss: 1.9558418989181519\n",
      "Epoch 225 >>>>>>>>>>>> loss: 1.939272403717041\n",
      "Epoch 226 >>>>>>>>>>>> loss: 1.9388213157653809\n",
      "Epoch 227 >>>>>>>>>>>> loss: 1.9439074993133545\n",
      "Epoch 228 >>>>>>>>>>>> loss: 1.939145565032959\n",
      "Epoch 229 >>>>>>>>>>>> loss: 1.9372241497039795\n",
      "Epoch 230 >>>>>>>>>>>> loss: 1.9331852197647095\n",
      "Epoch 231 >>>>>>>>>>>> loss: 1.935828685760498\n",
      "Epoch 232 >>>>>>>>>>>> loss: 1.9358566999435425\n",
      "Epoch 233 >>>>>>>>>>>> loss: 1.9299404621124268\n",
      "Epoch 234 >>>>>>>>>>>> loss: 1.9324101209640503\n",
      "Epoch 235 >>>>>>>>>>>> loss: 1.9433743953704834\n",
      "Epoch 236 >>>>>>>>>>>> loss: 1.9418244361877441\n",
      "Epoch 237 >>>>>>>>>>>> loss: 1.9323973655700684\n",
      "Epoch 238 >>>>>>>>>>>> loss: 1.926483154296875\n",
      "Epoch 239 >>>>>>>>>>>> loss: 1.9377577304840088\n",
      "Epoch 240 >>>>>>>>>>>> loss: 1.922168493270874\n",
      "Epoch 241 >>>>>>>>>>>> loss: 1.9289851188659668\n",
      "Epoch 242 >>>>>>>>>>>> loss: 1.9330717325210571\n",
      "Epoch 243 >>>>>>>>>>>> loss: 1.9447762966156006\n",
      "Epoch 244 >>>>>>>>>>>> loss: 1.9299834966659546\n",
      "Epoch 245 >>>>>>>>>>>> loss: 1.9327328205108643\n",
      "Epoch 246 >>>>>>>>>>>> loss: 1.9334907531738281\n",
      "Epoch 247 >>>>>>>>>>>> loss: 1.9343966245651245\n",
      "Epoch 248 >>>>>>>>>>>> loss: 1.9333810806274414\n",
      "Epoch 249 >>>>>>>>>>>> loss: 1.9360153675079346\n",
      "Epoch 250 >>>>>>>>>>>> loss: 1.9319703578948975\n",
      "Epoch 251 >>>>>>>>>>>> loss: 1.938043236732483\n",
      "Epoch 252 >>>>>>>>>>>> loss: 1.9261620044708252\n",
      "Epoch 253 >>>>>>>>>>>> loss: 1.928527593612671\n",
      "Epoch 254 >>>>>>>>>>>> loss: 1.9281152486801147\n",
      "Epoch 255 >>>>>>>>>>>> loss: 1.9210920333862305\n",
      "Epoch 256 >>>>>>>>>>>> loss: 1.9290169477462769\n",
      "Epoch 257 >>>>>>>>>>>> loss: 1.9272699356079102\n",
      "Epoch 258 >>>>>>>>>>>> loss: 1.9212672710418701\n",
      "Epoch 259 >>>>>>>>>>>> loss: 1.923990249633789\n",
      "Epoch 260 >>>>>>>>>>>> loss: 1.9180853366851807\n",
      "Epoch 261 >>>>>>>>>>>> loss: 1.9274581670761108\n",
      "Epoch 262 >>>>>>>>>>>> loss: 1.9328306913375854\n",
      "Epoch 263 >>>>>>>>>>>> loss: 1.927962064743042\n",
      "Epoch 264 >>>>>>>>>>>> loss: 1.919616937637329\n",
      "Epoch 265 >>>>>>>>>>>> loss: 1.9175984859466553\n",
      "Epoch 266 >>>>>>>>>>>> loss: 1.9144952297210693\n",
      "Epoch 267 >>>>>>>>>>>> loss: 1.9172104597091675\n",
      "Epoch 268 >>>>>>>>>>>> loss: 1.9238307476043701\n",
      "Epoch 269 >>>>>>>>>>>> loss: 1.916706919670105\n",
      "Epoch 270 >>>>>>>>>>>> loss: 1.9232208728790283\n",
      "Epoch 271 >>>>>>>>>>>> loss: 1.926440954208374\n",
      "Epoch 272 >>>>>>>>>>>> loss: 1.9215034246444702\n",
      "Epoch 273 >>>>>>>>>>>> loss: 1.9078303575515747\n",
      "Epoch 274 >>>>>>>>>>>> loss: 1.9212970733642578\n",
      "Epoch 275 >>>>>>>>>>>> loss: 1.9185352325439453\n",
      "Epoch 276 >>>>>>>>>>>> loss: 1.928939938545227\n",
      "Epoch 277 >>>>>>>>>>>> loss: 1.916055679321289\n",
      "Epoch 278 >>>>>>>>>>>> loss: 1.9183743000030518\n",
      "Epoch 279 >>>>>>>>>>>> loss: 1.925917625427246\n",
      "Epoch 280 >>>>>>>>>>>> loss: 1.9349323511123657\n",
      "Epoch 281 >>>>>>>>>>>> loss: 1.919762134552002\n",
      "Epoch 282 >>>>>>>>>>>> loss: 1.9170902967453003\n",
      "Epoch 283 >>>>>>>>>>>> loss: 1.9169193506240845\n",
      "Epoch 284 >>>>>>>>>>>> loss: 1.9224261045455933\n",
      "Epoch 285 >>>>>>>>>>>> loss: 1.921147346496582\n",
      "Epoch 286 >>>>>>>>>>>> loss: 1.916229248046875\n",
      "Epoch 287 >>>>>>>>>>>> loss: 1.9196110963821411\n",
      "Epoch 288 >>>>>>>>>>>> loss: 1.9218721389770508\n",
      "Epoch 289 >>>>>>>>>>>> loss: 1.9104783535003662\n",
      "Epoch 290 >>>>>>>>>>>> loss: 1.9265936613082886\n",
      "Epoch 291 >>>>>>>>>>>> loss: 1.9257051944732666\n",
      "Epoch 292 >>>>>>>>>>>> loss: 1.9201817512512207\n",
      "Epoch 293 >>>>>>>>>>>> loss: 1.9255034923553467\n",
      "Epoch 294 >>>>>>>>>>>> loss: 1.9195239543914795\n",
      "Epoch 295 >>>>>>>>>>>> loss: 1.922861099243164\n",
      "Epoch 296 >>>>>>>>>>>> loss: 1.9143171310424805\n",
      "Epoch 297 >>>>>>>>>>>> loss: 1.9209904670715332\n",
      "Epoch 298 >>>>>>>>>>>> loss: 1.911293864250183\n",
      "Epoch 299 >>>>>>>>>>>> loss: 1.9140441417694092\n",
      "Epoch 300 >>>>>>"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b183fcf4ae25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpretrain_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                     \u001b[0mrtn_history\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                     device=device)\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_fname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Creator\\Script\\Python\\Project\\irs_toolbox\\training\\contrastive_pretraining.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_loader, epochs, verbose, rtn_history, device)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Epoch {i+1} '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mitems\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Creator\\Script\\Python\\Project\\irs_toolbox\\data\\torchData\\utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mfp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mfp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepaths2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mX1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[0mX2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Creator\\Script\\Python\\Project\\irs_toolbox\\data\\torchData\\utils.py\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(fp, readtype)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mreadtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'npy'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"currently only support 'csv' or 'npy'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[1;32m--> 441\u001b[1;33m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[0;32m    442\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# Try a pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# We can use the fast fromfile() function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;31m# This is not a real file. We have to read it the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clr = Contrastive_PreTraining(encoder_builder=builder,\n",
    "                              batch_size=batch_size,\n",
    "                              supervision=supervision,\n",
    "                              temperature=temperature\n",
    "                              )\n",
    "\n",
    "encoder = clr.train(train_loader=pretrain_loader,\n",
    "                    epochs=pretrain_epochs,\n",
    "                    rtn_history=False,\n",
    "                    device=device)\n",
    "\n",
    "torch.save(encoder.state_dict(),model_fname)\n",
    "del encoder, clr, pretrain_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FINE-TUNING #####\n",
    "\n",
    "# data loading\n",
    "data_loading = DataLoading(transform=transform,batch_size=batch_size,readtype=readtype,\n",
    "                           num_workers=num_workers,drop_last=True)\n",
    "test_loading = DataLoading(transform=transform,batch_size=len(df_test),readtype=readtype,\n",
    "                           num_workers=num_workers,drop_last=True)\n",
    "\n",
    "df_train = df_train.rename({'fullpath_x':'fullpath'},axis=1)\n",
    "df_val = df_val.rename({'fullpath_x':'fullpath'},axis=1)\n",
    "df_test = df_test.rename({'fullpath_x':'fullpath'},axis=1)\n",
    "\n",
    "train_loader = data_loading(df_train)\n",
    "val_loader   = data_loading(df_val)\n",
    "test_loader  = test_loading(df_test)\n",
    "\n",
    "# load and create model\n",
    "model = FineTuneCNN(model_path=model_fname,\n",
    "                    encoder_builder=builder,\n",
    "                    hidden_layer=hidden_layer,\n",
    "                    n_classes=df.activity.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with poutyne\n",
    "mdl = Model(model,'adam','cross_entropy',\n",
    "            batch_metrics=['accuracy'],\n",
    "            epoch_metrics=[poutyne.F1('micro'),poutyne.F1('macro')]).to(device)\n",
    "history = mdl.fit_generator(train_generator=train_loader,valid_generator=test_loader,epochs=finetune_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
